Systems Information:

Clickhouse Instance: 192.168.5.60:9000

Cassandra Instance: dev-cassandra.ksg.int:9042

Clickhouse Table Definition:
CREATE TABLE radius.udr ( 
   CreateDate DateTime default now(), 
   Message String 
) ENGINE = MergeTree() 
PARTITION BY toYYYYMM(CreateDate) 
ORDER BY tuple()

Cassandra Table Definition:
CREATE TABLE "CassandraPractice".udr_copy1 (
	partitionhash int,
	hashcode text,
	accountnumber text,
	airtimeclass int,
	airtimeunits double,
	allocationcompletedate text,
	apn text,
	callednumber text,
	callingnumber text,
	carrierid int,
	cellid text,
	chargingid text,
	costcenterid int,
	downlinkvol bigint,
	duration double,
	exactusagedateonly date,
	exactusagetime text,
	fileid int,
	iccid text,
	imei text,
	imsi text,
	lineid bigint,
	linenumber int,
	mobilecountrycode text,
	mobilenetworkcode text,
	mobileoriginated boolean,
	msisdn text,
	network text,
	orgid int,
	orgurn text,
	plmn text,
	propertybag MAP<text, text>,
	recordtype text,
	roamingindicator text,
	roundingdate text,
	sender text,
	subscriptionid int,
	subscriptionurn text,
	surrecordtypeid int,
	tapcode text,
	uplinkvol bigint,
	usagetypeid int,
	PRIMARY KEY (partitionhash, hashcode)
) WITH bloom_filter_fp_chance = 0.01
AND comment = ''
AND crc_check_chance = 1.0
AND dclocal_read_repair_chance = 0.1
AND default_time_to_live = 0
AND gc_grace_seconds = 864000
AND max_index_interval = 2048
AND memtable_flush_period_in_ms = 0
AND min_index_interval = 128
AND read_repair_chance = 0.0
AND speculative_retry = '99.0PERCENTILE'
AND caching = {
	'keys' : 'NONE',
	'rows_per_partition' : 'NONE'
}
AND compression = {
	'chunk_length_in_kb' : 64,
	'class' : 'LZ4Compressor',
	'enabled' : true
}
AND compaction = {
	'class' : 'SizeTieredCompactionStrategy',
	'max_threshold' : 32,
	'min_threshold' : 4
};


Beginning Clickhouse Test
Thread 140203467540224 starting
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
LIMIT 
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 0: 0.05
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 0.08
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 0.06
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 3: 0.05
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 4: 0.06
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 0.06
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.11
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 0.04
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 0.03
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 29751 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 13, avg_chars_size = 6, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12040 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 9: 0.08
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.07

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.05 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.06 seconds
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.06
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.08
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 2: 0.06
Iteration 3: 0.09
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 4: 0.03
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 5: 0.05
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 6: 0.05
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 0.05
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 8: 0.02
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 9: 0.03
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.04

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.04 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.05 seconds
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 0.03
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 1: 0.05
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.12
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.04
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 4: 0.08
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 5: 0.07
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 6: 0.03
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 0.09
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.05
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113675 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 9: 0.06
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.04

Results for 100 records averaged over 11 repetitions:
Actual rows fetched: 100
Time to execute select: 0.05 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.06 seconds
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.06
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 0.07
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51795 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 0.09
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.06
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 4: 0.06
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 5: 0.08
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 6: 0.06
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 7: 0.07
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.08
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 9: 0.07
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.06

Results for 500 records averaged over 11 repetitions:
Actual rows fetched: 500
Time to execute select: 0.06 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.07 seconds
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 0: 0.18
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 0.09
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 0.10
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 3: 0.11
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 0.19
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113075 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 0.08
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.09
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 7: 0.09
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 11980 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 8: 0.12
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 0.08
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 0.08

Results for 1000 records averaged over 11 repetitions:
Actual rows fetched: 1000
Time to execute select: 0.10 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.11 seconds
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 0: 0.36
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.40
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92251 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 2: 0.31
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.35
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92371 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 4: 0.36
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113415 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.37
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 0.34
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 7: 0.37
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 8: 0.29
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 0.38
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 0.44

Results for 5000 records averaged over 11 repetitions:
Actual rows fetched: 5000
Time to execute select: 0.34 seconds
Time to put into dataframe: 0.03 seconds
Total time: 0.36 seconds
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 0.53
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 0.55
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 2: 0.50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12440 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.56
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 0.60
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 5: 0.50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113555 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.55
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 7: 0.53
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 0.58
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.47
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 0.51

Results for 10000 records averaged over 11 repetitions:
Actual rows fetched: 10000
Time to execute select: 0.49 seconds
Time to put into dataframe: 0.05 seconds
Total time: 0.54 seconds
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 4.90
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 4.72
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 4.20
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 3: 4.71
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 4: 4.21
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 4.48
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 6: 4.17
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 7: 4.26
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 8: 4.20
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 4.25
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 10: 4.21

Results for 100000 records averaged over 11 repetitions:
Actual rows fetched: 100000
Time to execute select: 3.73 seconds
Time to put into dataframe: 0.66 seconds
Total time: 4.39 seconds
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 20.96
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 1: 20.77
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 21.18
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 52055 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 21.25
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 4: 20.94
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 22.07
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12140 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 91891 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 6: 21.70
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 21.56
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 21.32
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 22.01
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 10: 21.04

Results for 500000 records averaged over 11 repetitions:
Actual rows fetched: 500000
Time to execute select: 17.74 seconds
Time to put into dataframe: 3.61 seconds
Total time: 21.35 seconds
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 0: 43.20
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 45.89
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 2: 42.37
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 3: 42.55
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 42.20
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 42.22
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 6: 42.95
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 44.61
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 43.10
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 9: 43.47
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 10: 43.46

Results for 1000000 records averaged over 11 repetitions:
Actual rows fetched: 1000000
Time to execute select: 35.95 seconds
Time to put into dataframe: 7.32 seconds
Total time: 43.27 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE partitionhash = -1 
LIMIT 
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 0: 2.54
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 1.79
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 2: 1.60
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 3: 1.59
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 4: 1.57
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 1.68
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 1.78
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 7: 1.78
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 1.72
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51595 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 1.67
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 10: 1.55

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 0
Time to execute select: 1.67 seconds
Time to put into dataframe: 0.08 seconds
Total time: 1.75 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE carrierid = 18000 
LIMIT 
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 0.19
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.24
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.10
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 3: 0.13
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 0.14
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 5: 0.11
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51495 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30191 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 0.13
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 7: 0.29
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 8: 0.21
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.09
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 10: 0.14

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.15 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.16 seconds
Iteration 0: 0.11
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 1: 0.10
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 131072 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 23, avg_chars_size = 18, limit = 5000): (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12080 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 2: 0.24
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.74
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 4: 0.13
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 0.20
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.17
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 0.08
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 8: 0.14
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 13, avg_chars_size = 6, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36025 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 9: 0.12
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 131072 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 23, avg_chars_size = 18, limit = 5000): (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 35985 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.10

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.18 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.19 seconds
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 0: 0.17
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.18
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 0.09
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 3: 0.12
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 4: 0.25
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.13
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 6: 0.11
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 7: 0.61
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 0.12
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 0.06
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113555 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.12

Results for 100 records averaged over 11 repetitions:
Actual rows fetched: 100
Time to execute select: 0.17 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.18 seconds
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 0.18
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 0.11
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 2: 0.14
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 13, avg_chars_size = 6, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 11980 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36525 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 3: 0.17
Iteration 4: 0.20
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 5: 0.13
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.12
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 7: 0.15
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.15
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 0.10
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 0.14

Results for 500 records averaged over 11 repetitions:
Actual rows fetched: 500
Time to execute select: 0.14 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.15 seconds
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 0: 0.12
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 1: 0.13
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 0.43
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36245 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.14
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 0.17
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.27
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.20
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 7: 0.19
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 11920 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 8: 0.21
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 0.13
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 0.45

Results for 1000 records averaged over 11 repetitions:
Actual rows fetched: 1000
Time to execute select: 0.21 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.22 seconds
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 0: 0.77
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 1: 0.66
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.69
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.60
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 4: 0.69
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 0.67
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 0.69
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 0.83
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 0.78
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 9: 0.66
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.53

Results for 5000 records averaged over 11 repetitions:
Actual rows fetched: 5000
Time to execute select: 0.65 seconds
Time to put into dataframe: 0.03 seconds
Total time: 0.69 seconds
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 0: 2.28
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 2.47
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 2: 2.16
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 1.98
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 1.86
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12280 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 1.96
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 1.97
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 2.04
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 8: 1.92
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 9: 1.82
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 1.92

Results for 10000 records averaged over 11 repetitions:
Actual rows fetched: 9997
Time to execute select: 1.97 seconds
Time to put into dataframe: 0.06 seconds
Total time: 2.03 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE fileid = 278 
LIMIT 
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30131 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 0: 0.19
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 1: 0.30
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 11980 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 2: 0.30
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 13, avg_chars_size = 6, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36245 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 0.21
Iteration 4: 0.20
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 0.25
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 0.25
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 7: 0.20
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.58
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.23
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 0.20

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.25 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.27 seconds
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.22
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.24
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 11980 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 0.26
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.19
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113595 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113575 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 4: 0.24
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 0.23
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.18
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 7: 0.28
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 0.20
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 9: 0.30
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.21

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.22 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.23 seconds
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 0.27
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 1: 0.25
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 0.24
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.25
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 0.21
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.58
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 6: 0.35
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 7: 0.22
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.22
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 0.27
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 0.24

Results for 100 records averaged over 11 repetitions:
Actual rows fetched: 100
Time to execute select: 0.27 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.28 seconds
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 0: 0.21
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 0.27
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 0.21
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.16
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 0.30
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 0.26
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 0.22
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 7: 0.21
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 0.18
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 9: 0.47
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 0.30

Results for 500 records averaged over 11 repetitions:
Actual rows fetched: 500
Time to execute select: 0.24 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.25 seconds
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 12340 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 0: 0.32
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 1: 0.23
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.23
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.26
Iteration 4: 0.20
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 5: 0.19
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.36
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 0.18
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 0.20
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 9: 0.22
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 0.37

Results for 1000 records averaged over 11 repetitions:
Actual rows fetched: 1000
Time to execute select: 0.24 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.25 seconds
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 0.33
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92171 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 0.35
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.31
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 3: 0.36
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 0.36
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 0.33
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.35
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.32
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.30
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 9: 0.36
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.32

Results for 5000 records averaged over 11 repetitions:
Actual rows fetched: 5000
Time to execute select: 0.31 seconds
Time to put into dataframe: 0.02 seconds
Total time: 0.34 seconds
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 0: 0.49
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 0.49
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 2: 0.47
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.55
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 0.52
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 5: 0.47
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 29631 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 1.24
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 7: 0.51
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 8: 0.49
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 9: 0.53
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.52

Results for 10000 records averaged over 11 repetitions:
Actual rows fetched: 10000
Time to execute select: 0.53 seconds
Time to put into dataframe: 0.05 seconds
Total time: 0.57 seconds
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 3.86
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 4.07
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 3.91
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 3.77
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 4.12
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 5: 4.43
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 3.81
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 3.84
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51795 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 8: 3.86
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 4.08
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 3.81

Results for 100000 records averaged over 11 repetitions:
Actual rows fetched: 100000
Time to execute select: 3.31 seconds
Time to put into dataframe: 0.65 seconds
Total time: 3.96 seconds
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 20.15
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 20.80
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 20.04
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 20.48
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 4: 20.07
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 19.91
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 6: 19.94
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 7: 20.09
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 8: 20.02
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 19.95
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 20.35

Results for 500000 records averaged over 11 repetitions:
Actual rows fetched: 500000
Time to execute select: 16.59 seconds
Time to put into dataframe: 3.57 seconds
Total time: 20.16 seconds
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113575 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 58.98
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 1: 45.78
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 44.96
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 3: 44.68
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113295 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 4: 45.10
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92251 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 5: 42.11
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 42.33
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 42.47
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 8: 42.35
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 42.05
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 41.38

Results for 1000000 records averaged over 11 repetitions:
Actual rows fetched: 1000000
Time to execute select: 37.42 seconds
Time to put into dataframe: 7.32 seconds
Total time: 44.74 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE usagetypeid = 0 
LIMIT 
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 1.69
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51855 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 1: 0.23
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12080 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 2: 0.18
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.20
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 4: 0.23
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 0.21
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 6: 0.23
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.39
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 0.21
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12280 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 9: 0.55
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 10: 0.22

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.31 seconds
Time to put into dataframe: 0.09 seconds
Total time: 0.40 seconds
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.18
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 0.19
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 2: 0.24
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30151 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 3: 0.24
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 4: 0.21
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 0.20
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.20
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 7: 0.26
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 0.21
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 0.20
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 10: 0.49

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.23 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.24 seconds
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.28
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 0.32
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.21
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.42
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12320 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 4: 0.20
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 0.21
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 6: 0.20
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 0.22
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.27
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 9: 0.19
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.30

Results for 100 records averaged over 11 repetitions:
Actual rows fetched: 100
Time to execute select: 0.24 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.26 seconds
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 0: 0.20
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 0.20
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 2: 0.21
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 3: 0.93
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 0.24
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 0.32
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.20
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 7: 0.24
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 8: 0.22
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.21
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.23

Results for 500 records averaged over 11 repetitions:
Actual rows fetched: 500
Time to execute select: 0.28 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.29 seconds
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.23
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 0.20
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 2: 0.21
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 0.23
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 0.34
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.25
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 0.30
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 7: 0.28
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 8: 0.30
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 9: 1.07
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 0.20

Results for 1000 records averaged over 11 repetitions:
Actual rows fetched: 1000
Time to execute select: 0.31 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.33 seconds
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 131072 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 23, avg_chars_size = 18, limit = 5000): (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12100 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 0.86
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 0.49
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.39
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 0.36
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 4: 0.30
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 5: 0.58
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.62
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.57
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.33
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 9: 0.35
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.33

Results for 5000 records averaged over 11 repetitions:
Actual rows fetched: 5000
Time to execute select: 0.45 seconds
Time to put into dataframe: 0.02 seconds
Total time: 0.47 seconds
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 0.52
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 0.59
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.56
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 3: 0.46
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 4: 0.65
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 0.50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 6: 0.50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 7: 0.46
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 0.55
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 0.49
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 0.52

Results for 10000 records averaged over 11 repetitions:
Actual rows fetched: 10000
Time to execute select: 0.48 seconds
Time to put into dataframe: 0.05 seconds
Total time: 0.53 seconds
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 4.01
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 1: 4.03
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 2: 3.87
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 3: 3.83
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 4: 3.99
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 3.75
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 6: 3.72
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 3.71
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 8: 3.73
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 9: 3.66
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 10: 3.74

Results for 100000 records averaged over 11 repetitions:
Actual rows fetched: 100000
Time to execute select: 3.19 seconds
Time to put into dataframe: 0.64 seconds
Total time: 3.82 seconds
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 0: 19.60
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 35765 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 20.72
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30031 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 19.79
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 12.7974, avg_chars_size = 5.75688, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30251 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 3: 20.40
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 20.08
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 5: 20.37
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 19.82
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 20.35
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 20.04
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 9: 20.58
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 10: 19.94

Results for 500000 records averaged over 11 repetitions:
Actual rows fetched: 500000
Time to execute select: 16.60 seconds
Time to put into dataframe: 3.56 seconds
Total time: 20.15 seconds
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.44 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 0: 42.25
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 1: 42.93
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 41.72
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Iteration 3: 51.71
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12240 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 44.52
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 5: 42.46
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.44 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30211 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 6: 42.69
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 41.13
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 42.10
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12200 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 11900 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 9: 41.24
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 10: 41.25

Results for 1000000 records averaged over 11 repetitions:
Actual rows fetched: 1000000
Time to execute select: 35.75 seconds
Time to put into dataframe: 7.34 seconds
Total time: 43.09 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE partitionhash < 190512005 
LIMIT 
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 0: 1.81
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 1: 0.14
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 2: 0.11
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.09
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 4: 0.11
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 0.11
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 6: 0.07
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 7: 0.14
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 0.18
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 9: 0.12
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 10: 0.22

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.19 seconds
Time to put into dataframe: 0.09 seconds
Total time: 0.28 seconds
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 0.14
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 1: 0.12
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 2: 0.08
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 3: 0.14
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 4: 0.09
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 0.11
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 6: 0.09
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 7: 0.09
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 0.15
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.16
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 0.14

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.11 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.12 seconds
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 13, avg_chars_size = 6, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 12100 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 0: 0.16
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.13
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 2: 0.15
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.15
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 4: 0.10
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.10
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 0.13
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 0.14
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113815 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 8: 0.11
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51255 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 9: 0.71
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 0.10

Results for 100 records averaged over 11 repetitions:
Actual rows fetched: 100
Time to execute select: 0.17 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.18 seconds
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 0: 0.10
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 1: 0.11
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.09
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 3: 0.12
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 0.12
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 5: 0.09
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 6: 0.18
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 7: 0.18
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 8: 0.26
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 0.15
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 10: 0.11

Results for 500 records averaged over 11 repetitions:
Actual rows fetched: 500
Time to execute select: 0.13 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.14 seconds
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 0: 0.24
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 1: 0.14
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.15
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.21
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51995 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 0.12
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 5: 0.41
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 6: 0.15
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 7: 0.15
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 8: 0.13
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 0.12
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 10: 0.16

Results for 1000 records averaged over 11 repetitions:
Actual rows fetched: 1000
Time to execute select: 0.17 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.18 seconds
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113535 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 0: 0.77
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 0.76
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.70
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 3: 0.45
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 0.62
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 5: 0.26
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 6: 0.27
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 0.26
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 0.28
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 0.30
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36165 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 1.14

Results for 5000 records averaged over 11 repetitions:
Actual rows fetched: 5000
Time to execute select: 0.50 seconds
Time to put into dataframe: 0.02 seconds
Total time: 0.53 seconds
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 0: 0.89
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 0.58
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.80
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 3: 0.50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 4: 0.51
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 0.47
Iteration 6: 0.44
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 7: 0.46
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 0.48
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 9: 0.47
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 10: 0.51

Results for 10000 records averaged over 11 repetitions:
Actual rows fetched: 10000
Time to execute select: 0.51 seconds
Time to put into dataframe: 0.05 seconds
Total time: 0.56 seconds
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 0: 3.99
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 4.41
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 3.92
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 3.80
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 29751 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 4: 4.05
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 5: 4.02
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 6: 3.92
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 7: 3.84
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 3.97
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 9: 4.01
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 10: 3.91

Results for 100000 records averaged over 11 repetitions:
Actual rows fetched: 100000
Time to execute select: 3.35 seconds
Time to put into dataframe: 0.64 seconds
Total time: 3.98 seconds
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 20.67
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 20.19
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 20.02
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 20.14
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 12.9842, avg_chars_size = 5.981039999999999, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51835 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12320 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 19.66
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 5: 20.56
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 6: 20.81
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 7: 20.58
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 8: 20.27
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 20.54
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 10: 20.35

Results for 500000 records averaged over 11 repetitions:
Actual rows fetched: 500000
Time to execute select: 16.74 seconds
Time to put into dataframe: 3.61 seconds
Total time: 20.35 seconds
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 0: 43.35
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Iteration 1: 43.81
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 44.54
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 3: 42.70
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51915 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 4: 42.92
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 5: 44.17
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 44.60
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 7: 46.13
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 8: 48.08
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51735 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 44.98
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 10: 43.75

Results for 1000000 records averaged over 11 repetitions:
Actual rows fetched: 1000000
Time to execute select: 37.00 seconds
Time to put into dataframe: 7.45 seconds
Total time: 44.46 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE subscriptionid < 11400 AND subscriptionid > 11360 
LIMIT 
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 0: 2.07
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 1: 0.15
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 29971 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.16
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.11
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 4: 0.13
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 5: 0.10
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 0.10
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 7: 0.20
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.28
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 9: 0.13
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 10: 0.12

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.21 seconds
Time to put into dataframe: 0.11 seconds
Total time: 0.32 seconds
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 0: 0.10
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.44 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 1: 0.11
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 2: 0.09
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92171 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.45
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 4: 0.13
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 5: 0.11
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 6: 0.13
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 7: 0.21
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 8: 0.20
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 0.68
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51915 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 32768 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 13, avg_chars_size = 6, limit = 5000): (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 11900 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 10: 0.82

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.26 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.28 seconds
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.18
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 0.31
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 2: 0.29
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 0.12
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 4: 0.08
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 5: 0.16
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.12
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36125 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 7: 0.10
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 8: 0.13
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 0.10
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30251 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 10: 0.16

Results for 100 records averaged over 11 repetitions:
Actual rows fetched: 100
Time to execute select: 0.15 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.16 seconds
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 0: 0.30
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 1: 0.12
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.13
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 3: 0.28
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 4: 0.12
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 0.41
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 6: 0.12
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 7: 0.14
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 8: 0.14
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 0.11
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 0.14

Results for 500 records averaged over 11 repetitions:
Actual rows fetched: 500
Time to execute select: 0.18 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.18 seconds
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 0.46
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 1: 0.23
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 0.17
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.13
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 4: 0.21
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 0.11
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 6: 0.14
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.13
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 8: 0.15
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 9: 0.15
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12240 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 10: 0.11

Results for 1000 records averaged over 11 repetitions:
Actual rows fetched: 1000
Time to execute select: 0.17 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.18 seconds
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 0: 0.33
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 1: 3.00
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.63
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 3: 0.28
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 4: 0.35
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 5: 0.30
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.44 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 0.48
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.29
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 0.29
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 9: 0.27
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 10: 0.30

Results for 5000 records averaged over 11 repetitions:
Actual rows fetched: 5000
Time to execute select: 0.57 seconds
Time to put into dataframe: 0.03 seconds
Total time: 0.59 seconds
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 0: 1.04
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 1: 0.63
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 0.95
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 0.54
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113615 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 0.54
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 0.61
Iteration 6: 0.76
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.73
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 8: 0.44
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.49
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 10: 0.48

Results for 10000 records averaged over 11 repetitions:
Actual rows fetched: 10000
Time to execute select: 0.61 seconds
Time to put into dataframe: 0.05 seconds
Total time: 0.66 seconds
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36245 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 0: 5.03
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 1: 4.75
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 4.64
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 3: 4.80
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 4: 4.78
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12040 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 5.29
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 6: 5.13
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 7: 4.67
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 4.96
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 9: 4.27
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 10: 4.42

Results for 100000 records averaged over 11 repetitions:
Actual rows fetched: 100000
Time to execute select: 4.14 seconds
Time to put into dataframe: 0.65 seconds
Total time: 4.80 seconds
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 11740 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Iteration 0: 22.54
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 1: 23.08
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 2: 22.54
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 23.30
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113275 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 23.15
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 5: 23.29
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 6: 23.45
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 7: 23.48
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113815 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 23.95
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 9: 24.36
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 12020 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 10: 23.95

Results for 500000 records averaged over 11 repetitions:
Actual rows fetched: 500000
Time to execute select: 19.76 seconds
Time to put into dataframe: 3.61 seconds
Total time: 23.37 seconds
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 36.29
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 1: 36.84
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 2: 35.98
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 3: 35.87
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113495 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 4: 41.08
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 5: 36.12
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 29831 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 6: 37.09
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 7: 36.46
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 8: 36.21
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 9: 36.32
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 91851 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 10: 42.58

Results for 1000000 records averaged over 11 repetitions:
Actual rows fetched: 779978
Time to execute select: 31.61 seconds
Time to put into dataframe: 5.74 seconds
Total time: 37.35 seconds

Current Query: SELECT visitParamExtractInt(Message, 'partitionhash') AS partitionhash, 
visitParamExtractString(Message, 'hashcode') AS hashcode, 
visitParamExtractString(Message, 'accountnumber') AS accountnumber, 
visitParamExtractInt(Message, 'airtimeclass') AS airtimeclass, 
visitParamExtractFloat(Message, 'airtimeunits') AS airtimeunits, 
visitParamExtractString(Message, 'allocationcompletedate') AS allocationcompletedate, 
visitParamExtractString(Message, 'apn') AS apn, 
visitParamExtractString(Message, 'callednumber') AS callednumber, 
visitParamExtractString(Message, 'callingnumber') AS callingnumber, 
visitParamExtractInt(Message, 'carrierid') AS carrierid, 
visitParamExtractString(Message, 'cellid') AS cellid, 
visitParamExtractString(Message, 'chargingid') AS chargingid, 
visitParamExtractInt(Message, 'costcenterid') AS costcenterid, 
visitParamExtractInt(Message, 'downlinkvol') AS downlinkvol, 
visitParamExtractFloat(Message, 'duration') AS duration, 
visitParamExtractString(Message, 'exactusagedateonly') AS exactusagedateonly, 
visitParamExtractString(Message, 'exactusagetime') AS exactusagetime, 
visitParamExtractInt(Message, 'fileid') AS fileid, 
visitParamExtractString(Message, 'iccid') AS iccid, 
visitParamExtractString(Message, 'imei') AS imei, 
visitParamExtractString(Message, 'imsi') AS imsi, 
visitParamExtractInt(Message, 'lineid') AS lineid, 
visitParamExtractInt(Message, 'linenumber') AS linenumber, 
visitParamExtractString(Message, 'mobilecountrycode') AS mobilecountrycode, 
visitParamExtractString(Message, 'mobilenetworkcode') AS mobilenetworkcode, 
visitParamExtractBool(Message, 'mobileoriginated') AS mobileoriginated, 
visitParamExtractString(Message, 'msisdn') AS msisdn, 
visitParamExtractString(Message, 'network') AS network, 
visitParamExtractInt(Message, 'orgid') AS orgid, 
visitParamExtractString(Message, 'orgurn') AS orgurn, 
visitParamExtractString(Message, 'plmn') AS plmn, 
visitParamExtractRaw(Message, 'propertybag') AS propertybag, 
visitParamExtractString(Message, 'recordtype') AS recordtype, 
visitParamExtractString(Message, 'roamingindicator') AS roamingindicator, 
visitParamExtractString(Message, 'roundingdate') AS roundingdate, 
visitParamExtractString(Message, 'sender') AS sender, 
visitParamExtractInt(Message, 'subscriptionid') AS subscriptionid, 
visitParamExtractString(Message, 'subscriptionurn') AS subscriptionurn, 
visitParamExtractInt(Message, 'surrecordtypeid') AS surrecordtypeid, 
visitParamExtractString(Message, 'tapcode') AS tapcode, 
visitParamExtractInt(Message, 'uplinkvol') AS uplinkvol, 
visitParamExtractInt(Message, 'usagetypeid') AS usagetypeid 
FROM radius.udr 
WHERE partitionhash = 190512005 AND subscriptionid < 11400 AND subscriptionid > 11360 
LIMIT 
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 0: 1.43
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 52035 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 1: 0.33
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Iteration 2: 0.17
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 3: 0.17
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Iteration 4: 0.29
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 5: 0.67
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 6: 0.19
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 7: 0.20
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 8: 0.15
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Iteration 9: 0.09
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 0.16

Results for 5 records averaged over 11 repetitions:
Actual rows fetched: 5
Time to execute select: 0.28 seconds
Time to put into dataframe: 0.07 seconds
Total time: 0.35 seconds
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Iteration 0: 0.17
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Iteration 1: 0.40
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 2: 0.12
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 3: 0.18
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 4: 0.16
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 5: 0.17
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92191 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 6: 0.15
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 7: 0.17
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Iteration 8: 0.21
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Iteration 9: 0.06
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Iteration 10: 0.25

Results for 10 records averaged over 11 repetitions:
Actual rows fetched: 10
Time to execute select: 0.18 seconds
Time to put into dataframe: 0.01 seconds
Total time: 0.19 seconds
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 0: 0.14
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Iteration 1: 0.18
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7fb94d2c1dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7fb94c5c3ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Iteration 2: 0.15
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Unexpected EOF while reading bytes
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Continuing after exception
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 encountered an exception:
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 encountered an exception:
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203467540224 encountered an exception:
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203206117120 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Thread 140203509548800 encountered an exception:
Code: 210. Connection refused (192.168.5.60:9000)
Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12360 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 11720 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113655 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113435 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 12520 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113475 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36085 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36085 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92651 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12520 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113695 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 91931 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113595 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36205 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51855 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36125 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 131072 bytes), maximum: 9.31 GiB: (avg_value_size_hint = 23, avg_chars_size = 18, limit = 5000): (while reading column ipv4_src_addr): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 29871 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server() [0x5cd9945]
5. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2d0) [0x5cdfa80]
6. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
7. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
8. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
9. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
10. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
12. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
13. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
14. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
15. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
16. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
17. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
18. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
19. clickhouse-server() [0x71eee5f]
20. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
21. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12280 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113655 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92371 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 16384 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 51915 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113715 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x1e7) [0x5944827]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203206117120 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203509548800 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.39 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::ColumnVector<int>::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x6d) [0x5ed0e1d]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203509548800 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113655 with max_rows_to_read = 5000). Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
18. clickhouse-server() [0x71eee5f]
19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203509548800 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203206117120 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203206117120 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203509548800 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203518002944 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
Thread 140203206117120 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
12. clickhouse-server() [0x71eee5f]
13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Continuing after exception
Thread 140203467540224 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
Thread 140203509548800 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
Thread 140203518002944 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203518002944 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203467540224 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203206117120 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
Thread 140203467540224 encountered an exception:
Code: 241.
DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:

0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
11. clickhouse-server() [0x71eee5f]
12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]

Continuing after exception
Thread 140203467540224 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
Thread 140203518002944 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
