2019-07-12 16:52:01.658846: Systems Information:
2019-07-12 16:52:01.659255: 
2019-07-12 16:52:01.659264: Clickhouse Instance: 192.168.5.60:9000
2019-07-12 16:52:01.659498: 
2019-07-12 16:52:01.659505: Cassandra Instance: dev-cassandra.ksg.int:9042
2019-07-12 16:52:01.659701: 
2019-07-12 16:52:01.659712: Clickhouse Table Definition:
2019-07-12 16:52:01.659712: CREATE TABLE radius.udr_other ( CreateDate DateTime default now(), partitionhash UInt64,hashcode String,carrierid UInt64,subscriptionid UInt64,Message String ) ENGINE = MergeTree() PARTITION BY toYYYYMM(CreateDate) order by partitionhash
2019-07-12 16:52:01.660842: 
2019-07-12 16:52:01.660849: Cassandra Table Definition:
2019-07-12 16:52:01.660849: CREATE TABLE "CassandraPractice".udr_copy1 (
2019-07-12 16:52:01.660849: 	partitionhash int,
2019-07-12 16:52:01.660849: 	hashcode text,
2019-07-12 16:52:01.660849: 	accountnumber text,
2019-07-12 16:52:01.660849: 	airtimeclass int,
2019-07-12 16:52:01.660849: 	airtimeunits double,
2019-07-12 16:52:01.660849: 	allocationcompletedate text,
2019-07-12 16:52:01.660849: 	apn text,
2019-07-12 16:52:01.660849: 	callednumber text,
2019-07-12 16:52:01.660849: 	callingnumber text,
2019-07-12 16:52:01.660849: 	carrierid int,
2019-07-12 16:52:01.660849: 	cellid text,
2019-07-12 16:52:01.660849: 	chargingid text,
2019-07-12 16:52:01.660849: 	costcenterid int,
2019-07-12 16:52:01.660849: 	downlinkvol bigint,
2019-07-12 16:52:01.660849: 	duration double,
2019-07-12 16:52:01.660849: 	exactusagedateonly date,
2019-07-12 16:52:01.660849: 	exactusagetime text,
2019-07-12 16:52:01.660849: 	fileid int,
2019-07-12 16:52:01.660849: 	iccid text,
2019-07-12 16:52:01.660849: 	imei text,
2019-07-12 16:52:01.660849: 	imsi text,
2019-07-12 16:52:01.660849: 	lineid bigint,
2019-07-12 16:52:01.660849: 	linenumber int,
2019-07-12 16:52:01.660849: 	mobilecountrycode text,
2019-07-12 16:52:01.660849: 	mobilenetworkcode text,
2019-07-12 16:52:01.660849: 	mobileoriginated boolean,
2019-07-12 16:52:01.660849: 	msisdn text,
2019-07-12 16:52:01.660849: 	network text,
2019-07-12 16:52:01.660849: 	orgid int,
2019-07-12 16:52:01.660849: 	orgurn text,
2019-07-12 16:52:01.660849: 	plmn text,
2019-07-12 16:52:01.660849: 	propertybag MAP<text, text>,
2019-07-12 16:52:01.660849: 	recordtype text,
2019-07-12 16:52:01.660849: 	roamingindicator text,
2019-07-12 16:52:01.660849: 	roundingdate text,
2019-07-12 16:52:01.660849: 	sender text,
2019-07-12 16:52:01.660849: 	subscriptionid int,
2019-07-12 16:52:01.660849: 	subscriptionurn text,
2019-07-12 16:52:01.660849: 	surrecordtypeid int,
2019-07-12 16:52:01.660849: 	tapcode text,
2019-07-12 16:52:01.660849: 	uplinkvol bigint,
2019-07-12 16:52:01.660849: 	usagetypeid int,
2019-07-12 16:52:01.660849: 	PRIMARY KEY (partitionhash, hashcode)
2019-07-12 16:52:01.660849: ) WITH bloom_filter_fp_chance = 0.01
2019-07-12 16:52:01.660849: AND comment = ''
2019-07-12 16:52:01.660849: AND crc_check_chance = 1.0
2019-07-12 16:52:01.660849: AND dclocal_read_repair_chance = 0.1
2019-07-12 16:52:01.660849: AND default_time_to_live = 0
2019-07-12 16:52:01.660849: AND gc_grace_seconds = 864000
2019-07-12 16:52:01.660849: AND max_index_interval = 2048
2019-07-12 16:52:01.660849: AND memtable_flush_period_in_ms = 0
2019-07-12 16:52:01.660849: AND min_index_interval = 128
2019-07-12 16:52:01.660849: AND read_repair_chance = 0.0
2019-07-12 16:52:01.660849: AND speculative_retry = '99.0PERCENTILE'
2019-07-12 16:52:01.660849: AND caching = {
2019-07-12 16:52:01.660849: 	'keys' : 'NONE',
2019-07-12 16:52:01.660849: 	'rows_per_partition' : 'NONE'
2019-07-12 16:52:01.660849: }
2019-07-12 16:52:01.660849: AND compression = {
2019-07-12 16:52:01.660849: 	'chunk_length_in_kb' : 64,
2019-07-12 16:52:01.660849: 	'class' : 'LZ4Compressor',
2019-07-12 16:52:01.660849: 	'enabled' : true
2019-07-12 16:52:01.660849: }
2019-07-12 16:52:01.660849: AND compaction = {
2019-07-12 16:52:01.660849: 	'class' : 'SizeTieredCompactionStrategy',
2019-07-12 16:52:01.660849: 	'max_threshold' : 32,
2019-07-12 16:52:01.660849: 	'min_threshold' : 4
2019-07-12 16:52:01.660849: };
2019-07-12 16:52:01.667428: 
2019-07-12 16:52:01.667437: 
2019-07-12 16:52:01.669992: Beginning Clickhouse Test
2019-07-12 16:52:01.720888: Thread 140286787585792 starting
2019-07-12 16:52:01.721598: Thread 140286787585792 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 16:52:02.721942: Thread 140286829594368 starting
2019-07-12 16:52:02.722532: Thread 140286829594368 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 16:52:03.723786: Thread 140286838048512 starting
2019-07-12 16:52:03.725360: Thread 140286838048512 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 16:52:04.726211: Thread 140286526359296 starting
2019-07-12 16:52:04.727853: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 16:52:05.727578: 
2019-07-12 16:52:05.727624: 
2019-07-12 16:52:05.727624: Current Schema: CH(JSON)
2019-07-12 16:52:05.729993: 
2019-07-12 16:52:05.730052: Current Query: Bulk Retrieval
2019-07-12 16:52:05.799432: Iteration 0: 0.07
2019-07-12 16:52:05.850019: Iteration 1: 0.05
2019-07-12 16:52:05.850824: Thread 140286787585792 encountered an exception:
2019-07-12 16:52:05.851051: Code: 241.
2019-07-12 16:52:05.851070: DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 16:52:05.851070: 
2019-07-12 16:52:05.851070: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 16:52:05.851070: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 16:52:05.851070: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 16:52:05.851070: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 16:52:05.851070: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 16:52:05.851070: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 16:52:05.851070: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 16:52:05.851070: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 16:52:05.851070: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 16:52:05.851070: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 16:52:05.851070: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 16:52:05.851070: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 16:52:05.851070: 12. clickhouse-server() [0x71eee5f]
2019-07-12 16:52:05.851070: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 16:52:05.851070: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 16:52:05.851070: 
2019-07-12 16:52:05.900368: Iteration 2: 0.05
2019-07-12 16:52:05.931845: Iteration 3: 0.03
2019-07-12 16:52:05.957302: Iteration 4: 0.02
2019-07-12 16:52:06.006197: Iteration 5: 0.05
2019-07-12 16:52:06.036803: Iteration 6: 0.03
2019-07-12 16:52:06.096887: Iteration 7: 0.06
2019-07-12 16:52:06.134698: Iteration 8: 0.04
2019-07-12 16:52:06.176190: Iteration 9: 0.04
2019-07-12 16:52:06.248393: Iteration 10: 0.07
2019-07-12 16:52:06.249013: 
2019-07-12 16:52:06.249022: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 16:52:06.249648: Actual rows fetched: 1
2019-07-12 16:52:06.250035: Time to execute select: 0.04 seconds
2019-07-12 16:52:06.250415: Time to put into dataframe: 0.01 seconds
2019-07-12 16:52:06.250600: Total time: 0.05 seconds
2019-07-12 16:52:06.276780: Iteration 0: 0.03
2019-07-12 16:52:06.302199: Iteration 1: 0.02
2019-07-12 16:52:06.324323: Iteration 2: 0.02
2019-07-12 16:52:06.370226: Iteration 3: 0.05
2019-07-12 16:52:06.433013: Iteration 4: 0.06
2019-07-12 16:52:06.484107: Iteration 5: 0.05
2019-07-12 16:52:06.520556: Iteration 6: 0.04
2019-07-12 16:52:06.579827: Iteration 7: 0.06
2019-07-12 16:52:06.620964: Iteration 8: 0.04
2019-07-12 16:52:06.668778: Iteration 9: 0.05
2019-07-12 16:52:06.796306: Iteration 10: 0.13
2019-07-12 16:52:06.796855: 
2019-07-12 16:52:06.796867: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 16:52:06.797674: Actual rows fetched: 10
2019-07-12 16:52:06.798085: Time to execute select: 0.04 seconds
2019-07-12 16:52:06.798492: Time to put into dataframe: 0.01 seconds
2019-07-12 16:52:06.798872: Total time: 0.05 seconds
2019-07-12 16:52:06.840999: Iteration 0: 0.04
2019-07-12 16:52:06.891643: Iteration 1: 0.05
2019-07-12 16:52:06.922350: Iteration 2: 0.03
2019-07-12 16:52:06.994913: Iteration 3: 0.07
2019-07-12 16:52:07.050730: Iteration 4: 0.06
2019-07-12 16:52:07.119891: Iteration 5: 0.07
2019-07-12 16:52:07.175272: Iteration 6: 0.05
2019-07-12 16:52:07.215003: Iteration 7: 0.04
2019-07-12 16:52:07.270551: Iteration 8: 0.05
2019-07-12 16:52:07.300002: Iteration 9: 0.03
2019-07-12 16:52:07.368985: Iteration 10: 0.07
2019-07-12 16:52:07.369538: 
2019-07-12 16:52:07.369546: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 16:52:07.370303: Actual rows fetched: 100
2019-07-12 16:52:07.370683: Time to execute select: 0.05 seconds
2019-07-12 16:52:07.371060: Time to put into dataframe: 0.00 seconds
2019-07-12 16:52:07.371433: Total time: 0.05 seconds
2019-07-12 16:52:07.464942: Iteration 0: 0.09
2019-07-12 16:52:07.537037: Iteration 1: 0.07
2019-07-12 16:52:07.620787: Iteration 2: 0.08
2019-07-12 16:52:07.691051: Iteration 3: 0.07
2019-07-12 16:52:07.770537: Iteration 4: 0.08
2019-07-12 16:52:07.845237: Iteration 5: 0.07
2019-07-12 16:52:07.912547: Iteration 6: 0.07
2019-07-12 16:52:08.029181: Iteration 7: 0.12
2019-07-12 16:52:08.132879: Iteration 8: 0.10
2019-07-12 16:52:08.205604: Iteration 9: 0.07
2019-07-12 16:52:08.276558: Iteration 10: 0.07
2019-07-12 16:52:08.277172: 
2019-07-12 16:52:08.277188: Results for 1000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 16:52:08.277900: Actual rows fetched: 1000
2019-07-12 16:52:08.278275: Time to execute select: 0.07 seconds
2019-07-12 16:52:08.278591: Time to put into dataframe: 0.01 seconds
2019-07-12 16:52:08.278863: Total time: 0.08 seconds
2019-07-12 16:52:08.805206: Iteration 0: 0.53
2019-07-12 16:52:09.433139: Iteration 1: 0.63
2019-07-12 16:52:10.037793: Iteration 2: 0.60
2019-07-12 16:52:10.561979: Iteration 3: 0.52
2019-07-12 16:52:10.859373: Continuing after exception
2019-07-12 16:52:10.861236: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 16:52:11.057875: Iteration 4: 0.50
2019-07-12 16:52:11.734236: Iteration 5: 0.68
2019-07-12 16:52:12.234184: Iteration 6: 0.50
2019-07-12 16:52:12.800832: Iteration 7: 0.57
2019-07-12 16:52:13.325272: Iteration 8: 0.52
2019-07-12 16:52:13.889674: Iteration 9: 0.56
2019-07-12 16:52:14.539071: Iteration 10: 0.65
2019-07-12 16:52:14.539671: 
2019-07-12 16:52:14.539679: Results for 10000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 16:52:14.540451: Actual rows fetched: 10000
2019-07-12 16:52:14.540838: Time to execute select: 0.52 seconds
2019-07-12 16:52:14.541176: Time to put into dataframe: 0.05 seconds
2019-07-12 16:52:14.541576: Total time: 0.57 seconds
2019-07-12 16:52:22.559429: Iteration 0: 8.02
2019-07-12 16:52:28.952557: Iteration 1: 6.39
2019-07-12 16:52:34.474482: Iteration 2: 5.52
2019-07-12 16:52:40.012915: Iteration 3: 5.54
2019-07-12 16:52:46.443594: Iteration 4: 6.43
2019-07-12 16:52:51.669525: Iteration 5: 5.23
2019-07-12 16:52:54.286081: Thread 140286526359296 encountered an exception:
2019-07-12 16:52:54.297875: Code: 241.
2019-07-12 16:52:54.297923: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 16:52:54.297923: 
2019-07-12 16:52:54.297923: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 16:52:54.297923: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 16:52:54.297923: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 16:52:54.297923: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 16:52:54.297923: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 16:52:54.297923: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 16:52:54.297923: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 16:52:54.297923: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 16:52:54.297923: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 16:52:54.297923: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 16:52:54.297923: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 16:52:54.297923: 11. clickhouse-server() [0x71eee5f]
2019-07-12 16:52:54.297923: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 16:52:54.297923: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 16:52:54.297923: 
2019-07-12 16:52:56.565808: Iteration 6: 4.90
2019-07-12 16:52:59.311221: Continuing after exception
2019-07-12 16:52:59.311850: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 16:53:01.832588: Iteration 7: 5.27
2019-07-12 16:53:08.373850: Iteration 8: 6.54
2019-07-12 16:53:13.876728: Iteration 9: 5.50
2019-07-12 16:53:15.002364: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 16:53:19.477308: Iteration 10: 5.60
2019-07-12 16:53:19.477803: 
2019-07-12 16:53:19.477812: Results for 100000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 16:53:19.478374: Actual rows fetched: 100000
2019-07-12 16:53:19.478774: Time to execute select: 5.18 seconds
2019-07-12 16:53:19.479112: Time to put into dataframe: 0.72 seconds
2019-07-12 16:53:19.479498: Total time: 5.90 seconds
2019-07-12 16:53:46.814525: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 16:54:11.571954: Iteration 0: 52.09
2019-07-12 16:54:18.611943: Thread 140286787585792 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 16:55:04.368803: Iteration 1: 52.80
2019-07-12 16:55:42.418592: Thread 140286829594368 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 16:55:56.631685: Iteration 2: 52.26
2019-07-12 16:56:00.784128: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 16:56:33.311963: Thread 140286838048512 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 16:56:41.279167: Thread 140286526359296 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 16:56:49.514177: Iteration 3: 52.88
2019-07-12 16:56:56.136214: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 16:57:40.253885: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 16:57:41.268792: Iteration 4: 51.75
2019-07-12 16:57:46.296941: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 16:57:55.314978: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 16:58:32.870544: Iteration 5: 51.60
2019-07-12 16:58:35.688855: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 16:58:44.571302: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 16:59:24.511548: Iteration 6: 51.64
2019-07-12 16:59:39.363542: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 16:59:48.425246: Thread 140286787585792 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 16:59:56.452719: Thread 140286787585792 encountered an exception:
2019-07-12 16:59:56.457652: Code: 241.
2019-07-12 16:59:56.457718: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 16:59:56.457718: 
2019-07-12 16:59:56.457718: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 16:59:56.457718: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 16:59:56.457718: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 16:59:56.457718: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 16:59:56.457718: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 16:59:56.457718: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 16:59:56.457718: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 16:59:56.457718: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 16:59:56.457718: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 16:59:56.457718: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 16:59:56.457718: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 16:59:56.457718: 11. clickhouse-server() [0x71eee5f]
2019-07-12 16:59:56.457718: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 16:59:56.457718: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 16:59:56.457718: 
2019-07-12 17:00:01.470727: Continuing after exception
2019-07-12 17:00:01.477808: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:00:14.653709: Iteration 7: 50.14
2019-07-12 17:00:17.735306: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:00:29.616012: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:00:49.090106: Thread 140286787585792 encountered an exception:
2019-07-12 17:00:49.102796: Code: 241.
2019-07-12 17:00:49.102828: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:00:49.102828: 
2019-07-12 17:00:49.102828: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:00:49.102828: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:00:49.102828: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:00:49.102828: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:00:49.102828: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:00:49.102828: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:00:49.102828: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:00:49.102828: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:00:49.102828: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:00:49.102828: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:00:49.102828: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:00:49.102828: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:00:49.102828: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:00:49.102828: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:00:49.102828: 
2019-07-12 17:00:54.130244: Continuing after exception
2019-07-12 17:00:54.133904: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:01:06.202933: Iteration 8: 51.55
2019-07-12 17:01:22.275587: Thread 140286526359296 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:01:55.312514: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:01:57.633786: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:02:10.652700: Thread 140286838048512 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:02:14.802643: Iteration 9: 68.60
2019-07-12 17:02:35.014299: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:03:05.427383: Iteration 10: 50.62
2019-07-12 17:03:05.427909: 
2019-07-12 17:03:05.427917: Results for 1000000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:03:05.428331: Actual rows fetched: 1000000
2019-07-12 17:03:05.428463: Time to execute select: 45.70 seconds
2019-07-12 17:03:05.428593: Time to put into dataframe: 7.57 seconds
2019-07-12 17:03:05.428705: Total time: 53.27 seconds
2019-07-12 17:03:05.428850: 
2019-07-12 17:03:05.428859: Current Query: Bulk Retreival: partitionhash = [-1000, -1]
2019-07-12 17:03:26.038757: Iteration 0: 20.61
2019-07-12 17:03:43.200146: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:03:45.810461: Iteration 1: 19.77
2019-07-12 17:03:48.757056: Thread 140286787585792 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:04:06.085340: Iteration 2: 20.25
2019-07-12 17:04:27.001254: Iteration 3: 20.91
2019-07-12 17:04:33.764222: Thread 140286526359296 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:04:41.783502: Thread 140286829594368 encountered an exception:
2019-07-12 17:04:41.785129: Code: 241.
2019-07-12 17:04:41.785204: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 52115 with max_rows_to_read = 5000). Stack trace:
2019-07-12 17:04:41.785204: 
2019-07-12 17:04:41.785204: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:04:41.785204: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:04:41.785204: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:04:41.785204: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:04:41.785204: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 17:04:41.785204: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 17:04:41.785204: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 17:04:41.785204: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 17:04:41.785204: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 17:04:41.785204: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 17:04:41.785204: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 17:04:41.785204: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 17:04:41.785204: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 17:04:41.785204: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 17:04:41.785204: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 17:04:41.785204: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 17:04:41.785204: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:04:41.785204: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:04:41.785204: 18. clickhouse-server() [0x71eee5f]
2019-07-12 17:04:41.785204: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:04:41.785204: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:04:41.785204: 
2019-07-12 17:04:46.011012: Iteration 4: 19.01
2019-07-12 17:04:46.794062: Continuing after exception
2019-07-12 17:04:46.794965: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:05:07.320417: Iteration 5: 21.31
2019-07-12 17:05:27.003385: Iteration 6: 19.68
2019-07-12 17:05:37.710334: Thread 140286787585792 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:05:44.253452: Thread 140286829594368 encountered an exception:
2019-07-12 17:05:44.254829: Code: 241.
2019-07-12 17:05:44.254878: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:05:44.254878: 
2019-07-12 17:05:44.254878: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:05:44.254878: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:05:44.254878: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:05:44.254878: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:05:44.254878: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:05:44.254878: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:05:44.254878: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:05:44.254878: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:05:44.254878: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:05:44.254878: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:05:44.254878: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:05:44.254878: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:05:44.254878: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:05:44.254878: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:05:44.254878: 
2019-07-12 17:05:46.875371: Iteration 7: 19.87
2019-07-12 17:05:49.261588: Continuing after exception
2019-07-12 17:05:49.262510: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:06:07.668708: Iteration 8: 20.79
2019-07-12 17:06:22.735969: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:06:27.037825: Thread 140286838048512 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:06:28.573173: Iteration 9: 20.90
2019-07-12 17:06:48.977330: Iteration 10: 20.40
2019-07-12 17:06:48.979055: 
2019-07-12 17:06:48.979127: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:06:48.980620: Actual rows fetched: 0
2019-07-12 17:06:48.981341: Time to execute select: 20.24 seconds
2019-07-12 17:06:48.982200: Time to put into dataframe: 0.07 seconds
2019-07-12 17:06:48.983002: Total time: 20.32 seconds
2019-07-12 17:06:48.983749: 
2019-07-12 17:06:48.983794: Current Query: Bulk Retreival: carrierid = [18000, 19000]
2019-07-12 17:06:49.160125: Iteration 0: 0.17
2019-07-12 17:06:49.396665: Iteration 1: 0.24
2019-07-12 17:06:49.543251: Iteration 2: 0.15
2019-07-12 17:06:49.762816: Iteration 3: 0.22
2019-07-12 17:06:49.895682: Iteration 4: 0.13
2019-07-12 17:06:50.033625: Iteration 5: 0.14
2019-07-12 17:06:50.206676: Iteration 6: 0.17
2019-07-12 17:06:50.392153: Iteration 7: 0.18
2019-07-12 17:06:50.465119: Iteration 8: 0.07
2019-07-12 17:06:50.683991: Iteration 9: 0.22
2019-07-12 17:06:50.895710: Iteration 10: 0.21
2019-07-12 17:06:50.896476: 
2019-07-12 17:06:50.896494: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:06:50.897387: Actual rows fetched: 1
2019-07-12 17:06:50.897892: Time to execute select: 0.16 seconds
2019-07-12 17:06:50.898285: Time to put into dataframe: 0.02 seconds
2019-07-12 17:06:50.898795: Total time: 0.17 seconds
2019-07-12 17:06:51.002582: Iteration 0: 0.10
2019-07-12 17:06:51.160643: Iteration 1: 0.16
2019-07-12 17:06:51.350455: Iteration 2: 0.19
2019-07-12 17:06:51.450863: Iteration 3: 0.10
2019-07-12 17:06:51.641839: Iteration 4: 0.19
2019-07-12 17:06:51.793301: Iteration 5: 0.15
2019-07-12 17:06:52.000592: Iteration 6: 0.21
2019-07-12 17:06:52.145835: Iteration 7: 0.14
2019-07-12 17:06:52.296194: Iteration 8: 0.15
2019-07-12 17:06:52.441172: Iteration 9: 0.14
2019-07-12 17:06:52.577346: Iteration 10: 0.14
2019-07-12 17:06:52.578461: 
2019-07-12 17:06:52.578486: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:06:52.579641: Actual rows fetched: 10
2019-07-12 17:06:52.580263: Time to execute select: 0.14 seconds
2019-07-12 17:06:52.580777: Time to put into dataframe: 0.02 seconds
2019-07-12 17:06:52.581268: Total time: 0.15 seconds
2019-07-12 17:06:52.761350: Iteration 0: 0.18
2019-07-12 17:06:52.968957: Iteration 1: 0.21
2019-07-12 17:06:53.147045: Iteration 2: 0.18
2019-07-12 17:06:53.681578: Iteration 3: 0.53
2019-07-12 17:06:53.803033: Iteration 4: 0.12
2019-07-12 17:06:53.979596: Iteration 5: 0.18
2019-07-12 17:06:54.131193: Iteration 6: 0.15
2019-07-12 17:06:54.277949: Iteration 7: 0.15
2019-07-12 17:06:54.595555: Iteration 8: 0.32
2019-07-12 17:06:54.683689: Iteration 9: 0.09
2019-07-12 17:06:54.886956: Iteration 10: 0.20
2019-07-12 17:06:54.887910: 
2019-07-12 17:06:54.887932: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:06:54.888933: Actual rows fetched: 100
2019-07-12 17:06:54.889477: Time to execute select: 0.20 seconds
2019-07-12 17:06:54.889975: Time to put into dataframe: 0.01 seconds
2019-07-12 17:06:54.890502: Total time: 0.21 seconds
2019-07-12 17:06:55.253508: Iteration 0: 0.36
2019-07-12 17:06:55.653452: Iteration 1: 0.40
2019-07-12 17:06:56.647150: Iteration 2: 0.99
2019-07-12 17:06:57.039316: Iteration 3: 0.39
2019-07-12 17:06:57.291808: Iteration 4: 0.25
2019-07-12 17:06:58.069896: Iteration 5: 0.78
2019-07-12 17:06:58.294766: Iteration 6: 0.22
2019-07-12 17:06:59.118082: Iteration 7: 0.82
2019-07-12 17:06:59.531020: Iteration 8: 0.41
2019-07-12 17:06:59.877285: Iteration 9: 0.35
2019-07-12 17:07:00.418907: Iteration 10: 0.54
2019-07-12 17:07:00.419461: 
2019-07-12 17:07:00.419474: Results for 1000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:07:00.419902: Actual rows fetched: 1000
2019-07-12 17:07:00.420102: Time to execute select: 0.48 seconds
2019-07-12 17:07:00.420291: Time to put into dataframe: 0.02 seconds
2019-07-12 17:07:00.420433: Total time: 0.50 seconds
2019-07-12 17:07:02.996111: Iteration 0: 2.58
2019-07-12 17:07:03.984484: Iteration 1: 0.99
2019-07-12 17:07:06.572276: Iteration 2: 2.59
2019-07-12 17:07:08.388389: Iteration 3: 1.82
2019-07-12 17:07:10.056395: Iteration 4: 1.67
2019-07-12 17:07:11.370865: Iteration 5: 1.31
2019-07-12 17:07:16.447025: Iteration 6: 5.08
2019-07-12 17:07:20.105085: Iteration 7: 3.66
2019-07-12 17:07:21.881615: Iteration 8: 1.78
2019-07-12 17:07:23.898012: Iteration 9: 2.02
2019-07-12 17:07:25.879448: Iteration 10: 1.98
2019-07-12 17:07:25.880097: 
2019-07-12 17:07:25.880113: Results for 10000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:07:25.880817: Actual rows fetched: 10000
2019-07-12 17:07:25.881208: Time to execute select: 2.24 seconds
2019-07-12 17:07:25.881590: Time to put into dataframe: 0.07 seconds
2019-07-12 17:07:25.881855: Total time: 2.31 seconds
2019-07-12 17:07:37.457508: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:07:43.559312: Iteration 0: 17.68
2019-07-12 17:08:05.228033: Iteration 1: 21.67
2019-07-12 17:08:15.575339: Thread 140286838048512 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:08:20.727047: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:08:26.674196: Iteration 2: 21.45
2019-07-12 17:08:44.501528: Iteration 3: 17.83
2019-07-12 17:08:56.113473: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:09:02.298192: Iteration 4: 17.80
2019-07-12 17:09:21.913242: Iteration 5: 19.61
2019-07-12 17:09:27.465962: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:09:38.975433: Iteration 6: 17.06
2019-07-12 17:09:52.794887: Thread 140286787585792 encountered an exception:
2019-07-12 17:09:52.797546: Code: 241.
2019-07-12 17:09:52.797599: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:09:52.797599: 
2019-07-12 17:09:52.797599: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:09:52.797599: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:09:52.797599: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:09:52.797599: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:09:52.797599: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:09:52.797599: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:09:52.797599: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:09:52.797599: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:09:52.797599: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:09:52.797599: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:09:52.797599: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:09:52.797599: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:09:52.797599: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:09:52.797599: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:09:52.797599: 
2019-07-12 17:09:57.804279: Continuing after exception
2019-07-12 17:09:57.804831: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:09:59.293981: Iteration 7: 20.32
2019-07-12 17:10:16.099968: Iteration 8: 16.81
2019-07-12 17:10:18.429401: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:10:20.337479: Thread 140286838048512 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:10:34.381259: Iteration 9: 18.28
2019-07-12 17:10:51.238774: Iteration 10: 16.86
2019-07-12 17:10:51.239201: 
2019-07-12 17:10:51.239209: Results for 100000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:10:51.239944: Actual rows fetched: 100000
2019-07-12 17:10:51.240322: Time to execute select: 17.96 seconds
2019-07-12 17:10:51.240497: Time to put into dataframe: 0.71 seconds
2019-07-12 17:10:51.240757: Total time: 18.67 seconds
2019-07-12 17:11:15.589205: Iteration 0: 24.35
2019-07-12 17:11:16.123119: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:11:29.480984: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:11:41.055633: Iteration 1: 25.47
2019-07-12 17:12:05.927676: Iteration 2: 24.87
2019-07-12 17:12:09.944915: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:12:30.583836: Iteration 3: 24.66
2019-07-12 17:12:54.082226: Iteration 4: 23.50
2019-07-12 17:13:18.539044: Iteration 5: 24.46
2019-07-12 17:13:25.404266: Thread 140286838048512 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:13:35.194655: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:13:43.047486: Iteration 6: 24.51
2019-07-12 17:14:07.997653: Iteration 7: 24.95
2019-07-12 17:14:33.176005: Iteration 8: 25.18
2019-07-12 17:14:45.550593: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:14:58.040555: Iteration 9: 24.86
2019-07-12 17:15:22.961832: Iteration 10: 24.92
2019-07-12 17:15:22.962330: 
2019-07-12 17:15:22.962339: Results for 1000000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:15:22.962757: Actual rows fetched: 120000
2019-07-12 17:15:22.962972: Time to execute select: 23.83 seconds
2019-07-12 17:15:22.963173: Time to put into dataframe: 0.87 seconds
2019-07-12 17:15:22.963381: Total time: 24.70 seconds
2019-07-12 17:15:22.963574: 
2019-07-12 17:15:22.963581: Current Query: Bulk Retreival: partitionhash <= [190512000, 190512039]
2019-07-12 17:15:23.245680: Iteration 0: 0.28
2019-07-12 17:15:23.457144: Iteration 1: 0.21
2019-07-12 17:15:23.598750: Iteration 2: 0.14
2019-07-12 17:15:23.761309: Iteration 3: 0.16
2019-07-12 17:15:24.014244: Iteration 4: 0.25
2019-07-12 17:15:24.198257: Iteration 5: 0.18
2019-07-12 17:15:24.396581: Iteration 6: 0.20
2019-07-12 17:15:24.607566: Iteration 7: 0.21
2019-07-12 17:15:24.720027: Iteration 8: 0.11
2019-07-12 17:15:24.922622: Iteration 9: 0.20
2019-07-12 17:15:25.042583: Iteration 10: 0.12
2019-07-12 17:15:25.043098: 
2019-07-12 17:15:25.043108: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:15:25.043557: Actual rows fetched: 1
2019-07-12 17:15:25.043682: Time to execute select: 0.16 seconds
2019-07-12 17:15:25.043794: Time to put into dataframe: 0.03 seconds
2019-07-12 17:15:25.044040: Total time: 0.19 seconds
2019-07-12 17:15:25.145064: Iteration 0: 0.10
2019-07-12 17:15:25.290600: Iteration 1: 0.14
2019-07-12 17:15:25.435014: Iteration 2: 0.14
2019-07-12 17:15:25.538918: Iteration 3: 0.10
2019-07-12 17:15:25.619966: Iteration 4: 0.08
2019-07-12 17:15:25.838520: Iteration 5: 0.22
2019-07-12 17:15:25.920767: Iteration 6: 0.08
2019-07-12 17:15:26.017613: Iteration 7: 0.10
2019-07-12 17:15:26.165365: Iteration 8: 0.15
2019-07-12 17:15:26.307921: Iteration 9: 0.14
2019-07-12 17:15:26.432532: Iteration 10: 0.12
2019-07-12 17:15:26.433553: 
2019-07-12 17:15:26.433571: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:15:26.434625: Actual rows fetched: 10
2019-07-12 17:15:26.435145: Time to execute select: 0.12 seconds
2019-07-12 17:15:26.435556: Time to put into dataframe: 0.01 seconds
2019-07-12 17:15:26.436072: Total time: 0.13 seconds
2019-07-12 17:15:26.538792: Iteration 0: 0.10
2019-07-12 17:15:26.625706: Iteration 1: 0.09
2019-07-12 17:15:26.811276: Iteration 2: 0.18
2019-07-12 17:15:26.942483: Iteration 3: 0.13
2019-07-12 17:15:27.057527: Iteration 4: 0.11
2019-07-12 17:15:27.274030: Iteration 5: 0.22
2019-07-12 17:15:27.460625: Iteration 6: 0.19
2019-07-12 17:15:27.608597: Iteration 7: 0.15
2019-07-12 17:15:27.747107: Iteration 8: 0.14
2019-07-12 17:15:27.829973: Iteration 9: 0.08
2019-07-12 17:15:27.956918: Iteration 10: 0.13
2019-07-12 17:15:27.957941: 
2019-07-12 17:15:27.957963: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:15:27.959177: Actual rows fetched: 100
2019-07-12 17:15:27.959739: Time to execute select: 0.13 seconds
2019-07-12 17:15:27.960385: Time to put into dataframe: 0.01 seconds
2019-07-12 17:15:27.960878: Total time: 0.14 seconds
2019-07-12 17:15:28.114403: Iteration 0: 0.15
2019-07-12 17:15:28.306931: Iteration 1: 0.19
2019-07-12 17:15:28.413883: Iteration 2: 0.11
2019-07-12 17:15:28.567483: Iteration 3: 0.15
2019-07-12 17:15:28.823005: Iteration 4: 0.25
2019-07-12 17:15:28.950087: Iteration 5: 0.13
2019-07-12 17:15:29.128876: Iteration 6: 0.18
2019-07-12 17:15:29.298168: Iteration 7: 0.17
2019-07-12 17:15:29.458823: Iteration 8: 0.16
2019-07-12 17:15:29.600763: Iteration 9: 0.14
2019-07-12 17:15:29.750855: Iteration 10: 0.15
2019-07-12 17:15:29.751457: 
2019-07-12 17:15:29.751468: Results for 1000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:15:29.751895: Actual rows fetched: 1000
2019-07-12 17:15:29.751989: Time to execute select: 0.15 seconds
2019-07-12 17:15:29.752094: Time to put into dataframe: 0.01 seconds
2019-07-12 17:15:29.752272: Total time: 0.16 seconds
2019-07-12 17:15:30.277354: Iteration 0: 0.52
2019-07-12 17:15:30.788390: Iteration 1: 0.51
2019-07-12 17:15:31.341758: Iteration 2: 0.55
2019-07-12 17:15:31.856742: Iteration 3: 0.51
2019-07-12 17:15:32.342916: Iteration 4: 0.49
2019-07-12 17:15:32.885623: Iteration 5: 0.54
2019-07-12 17:15:33.399091: Iteration 6: 0.51
2019-07-12 17:15:33.890041: Iteration 7: 0.49
2019-07-12 17:15:34.428757: Iteration 8: 0.54
2019-07-12 17:15:34.912886: Iteration 9: 0.48
2019-07-12 17:15:35.466394: Iteration 10: 0.55
2019-07-12 17:15:35.467000: 
2019-07-12 17:15:35.467008: Results for 10000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:15:35.467788: Actual rows fetched: 10000
2019-07-12 17:15:35.468182: Time to execute select: 0.47 seconds
2019-07-12 17:15:35.468569: Time to put into dataframe: 0.05 seconds
2019-07-12 17:15:35.468957: Total time: 0.52 seconds
2019-07-12 17:15:40.489501: Iteration 0: 5.02
2019-07-12 17:15:41.308824: Thread 140286526359296 encountered an exception:
2019-07-12 17:15:41.310638: Code: 241.
2019-07-12 17:15:41.310778: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:15:41.310778: 
2019-07-12 17:15:41.310778: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:15:41.310778: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:15:41.310778: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:15:41.310778: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:15:41.310778: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:15:41.310778: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:15:41.310778: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:15:41.310778: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:15:41.310778: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:15:41.310778: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:15:41.310778: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:15:41.310778: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:15:41.310778: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:15:41.310778: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:15:41.310778: 
2019-07-12 17:15:42.397984: Thread 140286787585792 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:15:44.714036: Iteration 1: 4.22
2019-07-12 17:15:46.334966: Continuing after exception
2019-07-12 17:15:46.341091: Thread 140286526359296 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:15:49.559753: Iteration 2: 4.85
2019-07-12 17:15:54.401517: Iteration 3: 4.84
2019-07-12 17:15:58.770394: Iteration 4: 4.37
2019-07-12 17:16:03.566039: Iteration 5: 4.79
2019-07-12 17:16:08.449732: Iteration 6: 4.88
2019-07-12 17:16:13.095921: Iteration 7: 4.65
2019-07-12 17:16:17.753451: Iteration 8: 4.66
2019-07-12 17:16:22.581777: Iteration 9: 4.83
2019-07-12 17:16:27.007715: Iteration 10: 4.43
2019-07-12 17:16:27.008260: 
2019-07-12 17:16:27.008268: Results for 100000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:16:27.009009: Actual rows fetched: 100000
2019-07-12 17:16:27.009397: Time to execute select: 4.03 seconds
2019-07-12 17:16:27.009740: Time to put into dataframe: 0.65 seconds
2019-07-12 17:16:27.010044: Total time: 4.68 seconds
2019-07-12 17:16:38.951429: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:17:16.020993: Iteration 0: 49.01
2019-07-12 17:17:16.842393: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:17:26.739403: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:17:30.109619: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:18:04.925439: Iteration 1: 48.90
2019-07-12 17:18:21.100460: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:18:31.536298: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:18:53.491497: Iteration 2: 48.56
2019-07-12 17:19:20.619988: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:19:35.860073: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:19:43.502000: Iteration 3: 50.01
2019-07-12 17:20:05.536484: Thread 140286526359296 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:20:15.729874: Thread 140286838048512 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:20:34.316661: Iteration 4: 50.81
2019-07-12 17:21:04.180841: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:21:24.460546: Iteration 5: 50.14
2019-07-12 17:21:59.633556: Thread 140286838048512 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:22:17.272772: Iteration 6: 52.81
2019-07-12 17:22:48.247338: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:22:51.309005: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 17:22:59.227784: Thread 140286526359296 encountered an exception:
2019-07-12 17:22:59.239633: Code: 241.
2019-07-12 17:22:59.239658: DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:22:59.239658: 
2019-07-12 17:22:59.239658: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:22:59.239658: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:22:59.239658: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:22:59.239658: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:22:59.239658: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 17:22:59.239658: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 17:22:59.239658: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 17:22:59.239658: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:22:59.239658: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:22:59.239658: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:22:59.239658: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:22:59.239658: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:22:59.239658: 12. clickhouse-server() [0x71eee5f]
2019-07-12 17:22:59.239658: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:22:59.239658: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:22:59.239658: 
2019-07-12 17:23:04.261901: Continuing after exception
2019-07-12 17:23:04.322857: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:23:07.421620: Iteration 7: 50.15
2019-07-12 17:23:15.459871: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:23:42.480174: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 17:23:50.790255: Thread 140286838048512 encountered an exception:
2019-07-12 17:23:50.802401: Code: 241.
2019-07-12 17:23:50.802446: DB::Exception: Memory limit (for query) exceeded: would use 9.33 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:23:50.802446: 
2019-07-12 17:23:50.802446: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:23:50.802446: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:23:50.802446: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:23:50.802446: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:23:50.802446: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 17:23:50.802446: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 17:23:50.802446: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 17:23:50.802446: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:23:50.802446: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:23:50.802446: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:23:50.802446: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:23:50.802446: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:23:50.802446: 12. clickhouse-server() [0x71eee5f]
2019-07-12 17:23:50.802446: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:23:50.802446: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:23:50.802446: 
2019-07-12 17:23:53.758886: Thread 140286526359296 encountered an exception:
2019-07-12 17:23:54.104633: Code: 241.
2019-07-12 17:23:54.104672: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 12380 with max_rows_to_read = 5000). Stack trace:
2019-07-12 17:23:54.104672: 
2019-07-12 17:23:54.104672: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:23:54.104672: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:23:54.104672: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:23:54.104672: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:23:54.104672: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 17:23:54.104672: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 17:23:54.104672: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 17:23:54.104672: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 17:23:54.104672: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 17:23:54.104672: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 17:23:54.104672: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 17:23:54.104672: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 17:23:54.104672: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 17:23:54.104672: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 17:23:54.104672: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 17:23:54.104672: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 17:23:54.104672: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:23:54.104672: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:23:54.104672: 18. clickhouse-server() [0x71eee5f]
2019-07-12 17:23:54.104672: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:23:54.104672: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:23:54.104672: 
2019-07-12 17:23:55.856386: Continuing after exception
2019-07-12 17:23:55.869923: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:23:58.846251: Iteration 8: 51.42
2019-07-12 17:23:59.854475: Continuing after exception
2019-07-12 17:23:59.855327: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:24:20.445161: Thread 140286829594368 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:24:46.567511: Iteration 9: 47.72
2019-07-12 17:24:47.940548: Thread 140286526359296 encountered an exception:
2019-07-12 17:24:47.952535: Code: 241.
2019-07-12 17:24:47.952593: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:24:47.952593: 
2019-07-12 17:24:47.952593: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:24:47.952593: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:24:47.952593: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:24:47.952593: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:24:47.952593: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:24:47.952593: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:24:47.952593: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:24:47.952593: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:24:47.952593: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:24:47.952593: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:24:47.952593: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:24:47.952593: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:24:47.952593: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:24:47.952593: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:24:47.952593: 
2019-07-12 17:24:52.975283: Continuing after exception
2019-07-12 17:24:52.975780: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:25:33.210341: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:25:35.757748: Iteration 10: 49.19
2019-07-12 17:25:35.758467: 
2019-07-12 17:25:35.758477: Results for 1000000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:25:35.758786: Actual rows fetched: 1000000
2019-07-12 17:25:35.758948: Time to execute select: 42.27 seconds
2019-07-12 17:25:35.759131: Time to put into dataframe: 7.62 seconds
2019-07-12 17:25:35.759368: Total time: 49.88 seconds
2019-07-12 17:25:35.759539: 
2019-07-12 17:25:35.759547: Current Query: Bulk Retreival: subscriptionid >= [11111, 11611] AND subscriptionid <= [11111, 11611]
2019-07-12 17:25:36.669252: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:25:37.465484: Iteration 0: 1.71
2019-07-12 17:25:37.573508: Iteration 1: 0.11
2019-07-12 17:25:37.686668: Iteration 2: 0.11
2019-07-12 17:25:37.831089: Iteration 3: 0.14
2019-07-12 17:25:37.961718: Iteration 4: 0.13
2019-07-12 17:25:38.093514: Iteration 5: 0.13
2019-07-12 17:25:38.215912: Iteration 6: 0.12
2019-07-12 17:25:38.368863: Iteration 7: 0.15
2019-07-12 17:25:38.498352: Iteration 8: 0.13
2019-07-12 17:25:38.621629: Iteration 9: 0.12
2019-07-12 17:25:38.734227: Iteration 10: 0.11
2019-07-12 17:25:38.735587: 
2019-07-12 17:25:38.735632: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:25:38.736719: Actual rows fetched: 1
2019-07-12 17:25:38.737125: Time to execute select: 0.18 seconds
2019-07-12 17:25:38.737521: Time to put into dataframe: 0.09 seconds
2019-07-12 17:25:38.737907: Total time: 0.27 seconds
2019-07-12 17:25:38.853805: Iteration 0: 0.12
2019-07-12 17:25:38.934330: Iteration 1: 0.08
2019-07-12 17:25:39.036579: Iteration 2: 0.10
2019-07-12 17:25:39.127111: Iteration 3: 0.09
2019-07-12 17:25:39.206499: Iteration 4: 0.08
2019-07-12 17:25:39.350377: Iteration 5: 0.14
2019-07-12 17:25:39.427811: Iteration 6: 0.08
2019-07-12 17:25:39.579743: Iteration 7: 0.15
2019-07-12 17:25:39.698223: Iteration 8: 0.12
2019-07-12 17:25:39.787235: Iteration 9: 0.09
2019-07-12 17:25:39.970345: Iteration 10: 0.18
2019-07-12 17:25:39.971372: 
2019-07-12 17:25:39.971395: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:25:39.972433: Actual rows fetched: 10
2019-07-12 17:25:39.972877: Time to execute select: 0.10 seconds
2019-07-12 17:25:39.973369: Time to put into dataframe: 0.01 seconds
2019-07-12 17:25:39.973770: Total time: 0.11 seconds
2019-07-12 17:25:40.087698: Iteration 0: 0.11
2019-07-12 17:25:40.183631: Iteration 1: 0.10
2019-07-12 17:25:40.302900: Iteration 2: 0.12
2019-07-12 17:25:40.406953: Iteration 3: 0.10
2019-07-12 17:25:40.508900: Iteration 4: 0.10
2019-07-12 17:25:40.594968: Iteration 5: 0.09
2019-07-12 17:25:40.747256: Iteration 6: 0.15
2019-07-12 17:25:40.895048: Iteration 7: 0.15
2019-07-12 17:25:40.989387: Iteration 8: 0.09
2019-07-12 17:25:41.079917: Iteration 9: 0.09
2019-07-12 17:25:41.212139: Iteration 10: 0.13
2019-07-12 17:25:41.212809: 
2019-07-12 17:25:41.212822: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:25:41.213691: Actual rows fetched: 100
2019-07-12 17:25:41.214094: Time to execute select: 0.10 seconds
2019-07-12 17:25:41.214530: Time to put into dataframe: 0.01 seconds
2019-07-12 17:25:41.214914: Total time: 0.11 seconds
2019-07-12 17:25:41.381574: Iteration 0: 0.17
2019-07-12 17:25:41.534758: Iteration 1: 0.15
2019-07-12 17:25:41.655314: Iteration 2: 0.12
2019-07-12 17:25:41.769709: Iteration 3: 0.11
2019-07-12 17:25:41.877741: Iteration 4: 0.11
2019-07-12 17:25:42.133311: Iteration 5: 0.26
2019-07-12 17:25:42.286452: Iteration 6: 0.15
2019-07-12 17:25:42.391788: Iteration 7: 0.10
2019-07-12 17:25:42.530912: Iteration 8: 0.14
2019-07-12 17:25:42.683656: Iteration 9: 0.15
2019-07-12 17:25:42.807217: Iteration 10: 0.12
2019-07-12 17:25:42.807763: 
2019-07-12 17:25:42.807773: Results for 1000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:25:42.808437: Actual rows fetched: 1000
2019-07-12 17:25:42.808830: Time to execute select: 0.13 seconds
2019-07-12 17:25:42.809167: Time to put into dataframe: 0.01 seconds
2019-07-12 17:25:42.809630: Total time: 0.14 seconds
2019-07-12 17:25:43.319795: Iteration 0: 0.51
2019-07-12 17:25:43.871599: Iteration 1: 0.55
2019-07-12 17:25:44.340234: Iteration 2: 0.47
2019-07-12 17:25:44.825750: Iteration 3: 0.48
2019-07-12 17:25:45.327952: Iteration 4: 0.50
2019-07-12 17:25:45.821468: Iteration 5: 0.49
2019-07-12 17:25:46.311974: Iteration 6: 0.49
2019-07-12 17:25:46.808758: Iteration 7: 0.50
2019-07-12 17:25:47.301369: Iteration 8: 0.49
2019-07-12 17:25:47.780812: Iteration 9: 0.48
2019-07-12 17:25:48.268735: Iteration 10: 0.49
2019-07-12 17:25:48.269376: 
2019-07-12 17:25:48.269386: Results for 10000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:25:48.269908: Actual rows fetched: 10000
2019-07-12 17:25:48.270296: Time to execute select: 0.45 seconds
2019-07-12 17:25:48.270707: Time to put into dataframe: 0.05 seconds
2019-07-12 17:25:48.271083: Total time: 0.50 seconds
2019-07-12 17:25:52.820401: Iteration 0: 4.55
2019-07-12 17:25:57.457815: Iteration 1: 4.64
2019-07-12 17:26:02.217194: Iteration 2: 4.76
2019-07-12 17:26:06.597096: Iteration 3: 4.38
2019-07-12 17:26:10.927304: Iteration 4: 4.33
2019-07-12 17:26:15.387974: Iteration 5: 4.46
2019-07-12 17:26:20.109452: Iteration 6: 4.72
2019-07-12 17:26:20.890591: Thread 140286829594368 encountered an exception:
2019-07-12 17:26:20.896906: Code: 241.
2019-07-12 17:26:20.896933: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:26:20.896933: 
2019-07-12 17:26:20.896933: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:26:20.896933: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:26:20.896933: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:26:20.896933: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:26:20.896933: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:26:20.896933: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:26:20.896933: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:26:20.896933: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:26:20.896933: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:26:20.896933: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:26:20.896933: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:26:20.896933: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:26:20.896933: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:26:20.896933: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:26:20.896933: 
2019-07-12 17:26:24.562549: Iteration 7: 4.45
2019-07-12 17:26:25.920220: Continuing after exception
2019-07-12 17:26:25.923170: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:26:29.195456: Iteration 8: 4.63
2019-07-12 17:26:33.754598: Iteration 9: 4.56
2019-07-12 17:26:33.755700: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:26:38.362638: Iteration 10: 4.61
2019-07-12 17:26:38.363071: 
2019-07-12 17:26:38.363080: Results for 100000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:26:38.363394: Actual rows fetched: 100000
2019-07-12 17:26:38.363605: Time to execute select: 3.90 seconds
2019-07-12 17:26:38.363822: Time to put into dataframe: 0.65 seconds
2019-07-12 17:26:38.364044: Total time: 4.55 seconds
2019-07-12 17:26:54.184436: Thread 140286787585792 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:27:18.377477: Thread 140286838048512 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:27:27.499314: Iteration 0: 49.13
2019-07-12 17:27:38.800362: Thread 140286526359296 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:28:12.438055: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:28:15.250287: Iteration 1: 47.75
2019-07-12 17:28:59.370727: Thread 140286829594368 encountered an exception:
2019-07-12 17:28:59.422671: Code: 241.
2019-07-12 17:28:59.422706: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:28:59.422706: 
2019-07-12 17:28:59.422706: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:28:59.422706: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:28:59.422706: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:28:59.422706: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:28:59.422706: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:28:59.422706: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:28:59.422706: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:28:59.422706: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:28:59.422706: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:28:59.422706: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:28:59.422706: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:28:59.422706: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:28:59.422706: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:28:59.422706: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:28:59.422706: 
2019-07-12 17:29:03.613644: Iteration 2: 48.36
2019-07-12 17:29:04.675034: Continuing after exception
2019-07-12 17:29:04.675959: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:29:07.173939: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:29:38.895724: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:29:52.708645: Iteration 3: 49.09
2019-07-12 17:29:54.921880: Thread 140286526359296 encountered an exception:
2019-07-12 17:29:54.933879: Code: 241.
2019-07-12 17:29:54.933907: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:29:54.933907: 
2019-07-12 17:29:54.933907: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:29:54.933907: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:29:54.933907: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:29:54.933907: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:29:54.933907: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:29:54.933907: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:29:54.933907: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:29:54.933907: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:29:54.933907: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:29:54.933907: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:29:54.933907: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:29:54.933907: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:29:54.933907: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:29:54.933907: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:29:54.933907: 
2019-07-12 17:29:59.954729: Continuing after exception
2019-07-12 17:29:59.955771: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:30:41.930833: Iteration 4: 49.22
2019-07-12 17:30:43.016034: Thread 140286829594368 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:30:59.414908: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:31:30.719972: Iteration 5: 48.79
2019-07-12 17:31:46.746335: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:32:19.697773: Iteration 6: 48.98
2019-07-12 17:33:07.398890: Iteration 7: 47.70
2019-07-12 17:33:21.552478: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:33:32.107245: Thread 140286829594368 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:33:42.701202: Thread 140286526359296 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:33:46.257345: Thread 140286838048512 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:33:55.191850: Iteration 8: 47.79
2019-07-12 17:34:26.996157: Thread 140286787585792 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:34:36.478425: Thread 140286829594368 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:34:42.813548: Iteration 9: 47.62
2019-07-12 17:35:15.203150: Thread 140286838048512 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:35:30.694267: Iteration 10: 47.88
2019-07-12 17:35:30.695012: 
2019-07-12 17:35:30.695021: Results for 1000000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:35:30.695321: Actual rows fetched: 1000000
2019-07-12 17:35:30.695445: Time to execute select: 40.74 seconds
2019-07-12 17:35:30.695661: Time to put into dataframe: 7.65 seconds
2019-07-12 17:35:30.695859: Total time: 48.39 seconds
2019-07-12 17:35:30.696088: 
2019-07-12 17:35:30.696096: Current Query: Bulk Retreival: partitionhash = [190512000, 190512039] AND subscriptionid >= [11111, 11611] AND subscriptionid <= [11111, 11611]
2019-07-12 17:35:34.157126: Iteration 0: 3.46
2019-07-12 17:35:34.349508: Iteration 1: 0.19
2019-07-12 17:35:35.019318: Iteration 2: 0.67
2019-07-12 17:35:39.394122: Iteration 3: 4.37
2019-07-12 17:35:41.849990: Iteration 4: 2.46
2019-07-12 17:35:41.956669: Iteration 5: 0.11
2019-07-12 17:35:44.394039: Iteration 6: 2.44
2019-07-12 17:35:44.476469: Iteration 7: 0.08
2019-07-12 17:35:44.617007: Iteration 8: 0.14
2019-07-12 17:35:47.541347: Iteration 9: 2.92
2019-07-12 17:35:48.002843: Iteration 10: 0.46
2019-07-12 17:35:48.003634: 
2019-07-12 17:35:48.003652: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:35:48.004674: Actual rows fetched: 1
2019-07-12 17:35:48.005193: Time to execute select: 1.47 seconds
2019-07-12 17:35:48.005652: Time to put into dataframe: 0.11 seconds
2019-07-12 17:35:48.006141: Total time: 1.57 seconds
2019-07-12 17:35:48.143047: Iteration 0: 0.14
2019-07-12 17:35:50.051603: Iteration 1: 1.91
2019-07-12 17:35:50.244844: Iteration 2: 0.19
2019-07-12 17:35:54.816774: Iteration 3: 4.57
2019-07-12 17:35:55.008377: Iteration 4: 0.19
2019-07-12 17:35:55.088715: Iteration 5: 0.08
2019-07-12 17:35:55.223386: Iteration 6: 0.13
2019-07-12 17:35:55.363327: Iteration 7: 0.14
2019-07-12 17:35:56.538869: Iteration 8: 1.17
2019-07-12 17:36:00.649806: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:36:03.157396: Iteration 9: 6.62
2019-07-12 17:36:03.285981: Iteration 10: 0.13
2019-07-12 17:36:03.286761: 
2019-07-12 17:36:03.286780: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:36:03.287820: Actual rows fetched: 10
2019-07-12 17:36:03.288328: Time to execute select: 1.37 seconds
2019-07-12 17:36:03.288775: Time to put into dataframe: 0.01 seconds
2019-07-12 17:36:03.289267: Total time: 1.39 seconds
2019-07-12 17:36:03.431185: Iteration 0: 0.14
2019-07-12 17:36:05.025136: Iteration 1: 1.59
2019-07-12 17:36:05.288753: Iteration 2: 0.26
2019-07-12 17:36:05.583513: Iteration 3: 0.29
2019-07-12 17:36:10.220380: Iteration 4: 4.64
2019-07-12 17:36:14.832950: Iteration 5: 4.61
2019-07-12 17:36:16.193594: Iteration 6: 1.36
2019-07-12 17:36:17.543571: Iteration 7: 1.35
2019-07-12 17:36:18.223082: Iteration 8: 0.68
2019-07-12 17:36:18.446491: Iteration 9: 0.22
2019-07-12 17:36:20.811709: Iteration 10: 2.36
2019-07-12 17:36:20.812295: 
2019-07-12 17:36:20.812309: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:36:20.812922: Actual rows fetched: 100
2019-07-12 17:36:20.813321: Time to execute select: 1.58 seconds
2019-07-12 17:36:20.813739: Time to put into dataframe: 0.01 seconds
2019-07-12 17:36:20.814134: Total time: 1.59 seconds
2019-07-12 17:36:21.791080: Iteration 0: 0.98
2019-07-12 17:36:25.594907: Iteration 1: 3.80
2019-07-12 17:36:28.000038: Iteration 2: 2.40
2019-07-12 17:36:28.151122: Iteration 3: 0.15
2019-07-12 17:36:29.961257: Iteration 4: 1.81
2019-07-12 17:36:33.108605: Iteration 5: 3.15
2019-07-12 17:36:34.847449: Iteration 6: 1.74
2019-07-12 17:36:35.061160: Iteration 7: 0.21
2019-07-12 17:36:38.018316: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:36:42.984482: Iteration 8: 7.92
2019-07-12 17:36:43.112927: Iteration 9: 0.13
2019-07-12 17:36:43.743678: Iteration 10: 0.63
2019-07-12 17:36:43.744418: 
2019-07-12 17:36:43.744430: Results for 1000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:36:43.744912: Actual rows fetched: 1000
2019-07-12 17:36:43.745330: Time to execute select: 2.07 seconds
2019-07-12 17:36:43.745553: Time to put into dataframe: 0.01 seconds
2019-07-12 17:36:43.745854: Total time: 2.08 seconds
2019-07-12 17:36:45.477046: Iteration 0: 1.73
2019-07-12 17:36:46.225468: Iteration 1: 0.75
2019-07-12 17:36:46.762106: Iteration 2: 0.54
2019-07-12 17:36:47.228659: Iteration 3: 0.47
2019-07-12 17:36:50.145950: Iteration 4: 2.92
2019-07-12 17:36:53.605740: Iteration 5: 3.46
2019-07-12 17:36:56.777177: Iteration 6: 3.17
2019-07-12 17:36:57.586299: Iteration 7: 0.81
2019-07-12 17:37:01.008493: Iteration 8: 3.42
2019-07-12 17:37:01.612879: Iteration 9: 0.60
2019-07-12 17:37:02.737643: Iteration 10: 1.12
2019-07-12 17:37:02.738173: 
2019-07-12 17:37:02.738182: Results for 10000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:37:02.738829: Actual rows fetched: 10000
2019-07-12 17:37:02.738950: Time to execute select: 1.66 seconds
2019-07-12 17:37:02.739349: Time to put into dataframe: 0.07 seconds
2019-07-12 17:37:02.739707: Total time: 1.73 seconds
2019-07-12 17:37:07.530484: Iteration 0: 4.79
2019-07-12 17:37:14.910274: Iteration 1: 7.38
2019-07-12 17:37:19.306549: Iteration 2: 4.40
2019-07-12 17:37:27.143754: Iteration 3: 7.84
2019-07-12 17:37:28.528513: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:37:37.471459: Iteration 4: 10.33
2019-07-12 17:37:44.216518: Iteration 5: 6.74
2019-07-12 17:37:54.400410: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:37:54.778765: Iteration 6: 10.56
2019-07-12 17:37:59.071613: Iteration 7: 4.29
2019-07-12 17:38:06.252360: Iteration 8: 7.18
2019-07-12 17:38:11.795161: Iteration 9: 5.54
2019-07-12 17:38:20.106428: Iteration 10: 8.31
2019-07-12 17:38:20.106906: 
2019-07-12 17:38:20.106915: Results for 100000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:38:20.107339: Actual rows fetched: 100000
2019-07-12 17:38:20.107578: Time to execute select: 6.36 seconds
2019-07-12 17:38:20.107800: Time to put into dataframe: 0.68 seconds
2019-07-12 17:38:20.108021: Total time: 7.03 seconds
2019-07-12 17:38:55.310855: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:39:04.677693: Iteration 0: 44.57
2019-07-12 17:39:08.584394: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:39:23.886697: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:39:32.863724: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:40:01.920218: Iteration 1: 57.24
2019-07-12 17:40:15.167527: Thread 140286787585792 encountered an exception:
2019-07-12 17:40:15.179842: Code: 241.
2019-07-12 17:40:15.179866: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:40:15.179866: 
2019-07-12 17:40:15.179866: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:40:15.179866: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:40:15.179866: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:40:15.179866: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:40:15.179866: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:40:15.179866: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:40:15.179866: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:40:15.179866: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:40:15.179866: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:40:15.179866: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:40:15.179866: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:40:15.179866: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:40:15.179866: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:40:15.179866: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:40:15.179866: 
2019-07-12 17:40:20.207173: Continuing after exception
2019-07-12 17:40:20.213558: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:40:36.952887: Thread 140286829594368 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 17:40:45.676122: Thread 140286829594368 encountered an exception:
2019-07-12 17:40:45.891742: Code: 241.
2019-07-12 17:40:45.891769: DB::Exception: Memory limit (for query) exceeded: would use 9.38 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:40:45.891769: 
2019-07-12 17:40:45.891769: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:40:45.891769: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:40:45.891769: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:40:45.891769: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:40:45.891769: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 17:40:45.891769: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 17:40:45.891769: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 17:40:45.891769: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:40:45.891769: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:40:45.891769: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:40:45.891769: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:40:45.891769: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:40:45.891769: 12. clickhouse-server() [0x71eee5f]
2019-07-12 17:40:45.891769: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:40:45.891769: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:40:45.891769: 
2019-07-12 17:40:51.039772: Iteration 2: 49.12
2019-07-12 17:40:51.965007: Continuing after exception
2019-07-12 17:40:51.971868: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:40:54.376289: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:41:20.159262: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 17:41:29.020868: Thread 140286838048512 encountered an exception:
2019-07-12 17:41:29.028905: Code: 241.
2019-07-12 17:41:29.028932: DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:41:29.028932: 
2019-07-12 17:41:29.028932: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:41:29.028932: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:41:29.028932: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:41:29.028932: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:41:29.028932: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 17:41:29.028932: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 17:41:29.028932: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 17:41:29.028932: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:41:29.028932: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:41:29.028932: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:41:29.028932: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:41:29.028932: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:41:29.028932: 12. clickhouse-server() [0x71eee5f]
2019-07-12 17:41:29.028932: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:41:29.028932: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:41:29.028932: 
2019-07-12 17:41:34.076125: Continuing after exception
2019-07-12 17:41:34.965326: Thread 140286838048512 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:41:40.705478: Iteration 3: 49.66
2019-07-12 17:42:03.541790: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:42:15.218307: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:42:30.881026: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:42:34.306181: Iteration 4: 53.60
2019-07-12 17:42:57.940542: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:43:27.920900: Iteration 5: 53.61
2019-07-12 17:43:35.900599: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:43:57.041103: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:44:12.425311: Iteration 6: 44.50
2019-07-12 17:44:26.368745: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:44:53.623773: Iteration 7: 41.20
2019-07-12 17:45:30.826834: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:45:42.967915: Iteration 8: 49.34
2019-07-12 17:45:54.191899: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:46:07.060426: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:46:34.031858: Iteration 9: 51.06
2019-07-12 17:46:54.635002: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:47:21.150384: Iteration 10: 47.12
2019-07-12 17:47:21.151193: 
2019-07-12 17:47:21.151203: Results for 1000000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:47:21.151465: Actual rows fetched: 704760
2019-07-12 17:47:21.151730: Time to execute select: 42.22 seconds
2019-07-12 17:47:21.151908: Time to put into dataframe: 6.96 seconds
2019-07-12 17:47:21.152083: Total time: 49.18 seconds
2019-07-12 17:47:21.152253: 
2019-07-12 17:47:21.152273: Current Query: Partition Key Lookup: partitionhash = [190512000, 190512039]
2019-07-12 17:47:22.702003: Iteration 0: 1.55
2019-07-12 17:47:22.834660: Iteration 1: 0.13
2019-07-12 17:47:23.090781: Iteration 2: 0.25
2019-07-12 17:47:23.317576: Iteration 3: 0.23
2019-07-12 17:47:24.849308: Iteration 4: 1.53
2019-07-12 17:47:25.011235: Iteration 5: 0.16
2019-07-12 17:47:25.118596: Iteration 6: 0.10
2019-07-12 17:47:25.250099: Iteration 7: 0.13
2019-07-12 17:47:25.343095: Iteration 8: 0.09
2019-07-12 17:47:25.547485: Iteration 9: 0.20
2019-07-12 17:47:25.650891: Iteration 10: 0.10
2019-07-12 17:47:25.651733: 
2019-07-12 17:47:25.651750: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:47:25.652633: Actual rows fetched: 1
2019-07-12 17:47:25.653110: Time to execute select: 0.32 seconds
2019-07-12 17:47:25.653599: Time to put into dataframe: 0.08 seconds
2019-07-12 17:47:25.654076: Total time: 0.41 seconds
2019-07-12 17:47:25.810313: Iteration 0: 0.16
2019-07-12 17:47:26.000463: Iteration 1: 0.19
2019-07-12 17:47:26.106249: Iteration 2: 0.10
2019-07-12 17:47:26.213302: Iteration 3: 0.11
2019-07-12 17:47:26.317071: Iteration 4: 0.10
2019-07-12 17:47:26.490512: Iteration 5: 0.17
2019-07-12 17:47:26.616639: Iteration 6: 0.13
2019-07-12 17:47:26.694108: Iteration 7: 0.08
2019-07-12 17:47:26.790429: Iteration 8: 0.10
2019-07-12 17:47:26.905965: Iteration 9: 0.11
2019-07-12 17:47:27.027154: Iteration 10: 0.12
2019-07-12 17:47:27.027973: 
2019-07-12 17:47:27.027993: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:47:27.028954: Actual rows fetched: 10
2019-07-12 17:47:27.029499: Time to execute select: 0.11 seconds
2019-07-12 17:47:27.029993: Time to put into dataframe: 0.01 seconds
2019-07-12 17:47:27.030525: Total time: 0.12 seconds
2019-07-12 17:47:27.186923: Iteration 0: 0.16
2019-07-12 17:47:27.290943: Iteration 1: 0.10
2019-07-12 17:47:27.450914: Iteration 2: 0.16
2019-07-12 17:47:27.735261: Iteration 3: 0.28
2019-07-12 17:47:27.855338: Iteration 4: 0.12
2019-07-12 17:47:28.013620: Iteration 5: 0.16
2019-07-12 17:47:28.117291: Iteration 6: 0.10
2019-07-12 17:47:28.219743: Iteration 7: 0.10
2019-07-12 17:47:28.567377: Iteration 8: 0.35
2019-07-12 17:47:28.724907: Iteration 9: 0.16
2019-07-12 17:47:28.827398: Iteration 10: 0.10
2019-07-12 17:47:28.828074: 
2019-07-12 17:47:28.828085: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:47:28.828829: Actual rows fetched: 100
2019-07-12 17:47:28.829115: Time to execute select: 0.15 seconds
2019-07-12 17:47:28.829485: Time to put into dataframe: 0.01 seconds
2019-07-12 17:47:28.829864: Total time: 0.16 seconds
2019-07-12 17:47:29.036849: Iteration 0: 0.21
2019-07-12 17:47:29.257258: Iteration 1: 0.22
2019-07-12 17:47:29.390343: Iteration 2: 0.13
2019-07-12 17:47:29.504532: Iteration 3: 0.11
2019-07-12 17:47:29.618746: Iteration 4: 0.11
2019-07-12 17:47:29.828572: Iteration 5: 0.21
2019-07-12 17:47:29.976755: Iteration 6: 0.15
2019-07-12 17:47:30.169055: Iteration 7: 0.19
2019-07-12 17:47:30.334181: Iteration 8: 0.16
2019-07-12 17:47:30.513667: Iteration 9: 0.18
2019-07-12 17:47:30.693491: Iteration 10: 0.18
2019-07-12 17:47:30.694164: 
2019-07-12 17:47:30.694172: Results for 1000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:47:30.694976: Actual rows fetched: 1000
2019-07-12 17:47:30.695306: Time to execute select: 0.16 seconds
2019-07-12 17:47:30.695520: Time to put into dataframe: 0.01 seconds
2019-07-12 17:47:30.695907: Total time: 0.17 seconds
2019-07-12 17:47:31.199819: Iteration 0: 0.50
2019-07-12 17:47:31.736544: Iteration 1: 0.54
2019-07-12 17:47:32.285131: Iteration 2: 0.55
2019-07-12 17:47:34.228755: Iteration 3: 1.94
2019-07-12 17:47:34.510907: Thread 140286829594368 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 17:47:34.764466: Iteration 4: 0.54
2019-07-12 17:47:35.319025: Iteration 5: 0.55
2019-07-12 17:47:35.850793: Iteration 6: 0.53
2019-07-12 17:47:36.578865: Iteration 7: 0.73
2019-07-12 17:47:37.082862: Iteration 8: 0.50
2019-07-12 17:47:37.592114: Iteration 9: 0.51
2019-07-12 17:47:38.086986: Iteration 10: 0.49
2019-07-12 17:47:38.087387: 
2019-07-12 17:47:38.087395: Results for 10000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:47:38.087616: Actual rows fetched: 10000
2019-07-12 17:47:38.087729: Time to execute select: 0.62 seconds
2019-07-12 17:47:38.087838: Time to put into dataframe: 0.05 seconds
2019-07-12 17:47:38.087941: Total time: 0.67 seconds
2019-07-12 17:47:42.635826: Iteration 0: 4.55
2019-07-12 17:47:43.160779: Thread 140286829594368 encountered an exception:
2019-07-12 17:47:43.164955: Code: 241.
2019-07-12 17:47:43.165022: DB::Exception: Memory limit (for query) exceeded: would use 9.35 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:47:43.165022: 
2019-07-12 17:47:43.165022: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:47:43.165022: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:47:43.165022: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:47:43.165022: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:47:43.165022: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 17:47:43.165022: 5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
2019-07-12 17:47:43.165022: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
2019-07-12 17:47:43.165022: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:47:43.165022: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:47:43.165022: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:47:43.165022: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:47:43.165022: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:47:43.165022: 12. clickhouse-server() [0x71eee5f]
2019-07-12 17:47:43.165022: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:47:43.165022: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:47:43.165022: 
2019-07-12 17:47:46.926472: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:47:47.828362: Iteration 1: 5.19
2019-07-12 17:47:48.186093: Continuing after exception
2019-07-12 17:47:48.191415: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:47:52.377550: Iteration 2: 4.55
2019-07-12 17:47:57.178669: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:47:57.288677: Iteration 3: 4.91
2019-07-12 17:48:02.690574: Iteration 4: 5.40
2019-07-12 17:48:07.090949: Iteration 5: 4.40
2019-07-12 17:48:11.626329: Iteration 6: 4.53
2019-07-12 17:48:15.590664: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:48:16.260998: Iteration 7: 4.63
2019-07-12 17:48:20.539436: Iteration 8: 4.28
2019-07-12 17:48:25.102586: Iteration 9: 4.56
2019-07-12 17:48:30.287346: Iteration 10: 5.18
2019-07-12 17:48:30.287794: 
2019-07-12 17:48:30.287803: Results for 100000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:48:30.288133: Actual rows fetched: 100000
2019-07-12 17:48:30.288307: Time to execute select: 4.07 seconds
2019-07-12 17:48:30.288525: Time to put into dataframe: 0.68 seconds
2019-07-12 17:48:30.288737: Total time: 4.74 seconds
2019-07-12 17:48:41.305864: Thread 140286526359296 encountered an exception:
2019-07-12 17:48:41.307898: Code: 241.
2019-07-12 17:48:41.307926: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:48:41.307926: 
2019-07-12 17:48:41.307926: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:48:41.307926: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:48:41.307926: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:48:41.307926: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:48:41.307926: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:48:41.307926: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:48:41.307926: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:48:41.307926: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:48:41.307926: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:48:41.307926: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:48:41.307926: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:48:41.307926: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:48:41.307926: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:48:41.307926: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:48:41.307926: 
2019-07-12 17:48:46.324187: Continuing after exception
2019-07-12 17:48:46.333013: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:49:19.014830: Iteration 0: 48.73
2019-07-12 17:49:42.117752: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:49:44.663407: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:50:08.647647: Iteration 1: 49.63
2019-07-12 17:50:35.465405: Thread 140286526359296 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:50:56.993486: Iteration 2: 48.34
2019-07-12 17:51:27.403512: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:51:29.007006: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:51:46.803041: Iteration 3: 49.81
2019-07-12 17:52:10.018249: Thread 140286526359296 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:52:11.238009: Thread 140286787585792 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 17:52:36.398419: Iteration 4: 49.59
2019-07-12 17:53:15.217835: Thread 140286838048512 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:53:24.913512: Iteration 5: 48.51
2019-07-12 17:53:45.701968: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:54:14.169324: Iteration 6: 49.25
2019-07-12 17:54:22.571617: Thread 140286829594368 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:54:30.627443: Thread 140286838048512 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:55:02.741438: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 17:55:03.506455: Iteration 7: 49.34
2019-07-12 17:55:17.856043: Thread 140286838048512 encountered an exception:
2019-07-12 17:55:17.856712: Code: 241.
2019-07-12 17:55:17.856747: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 12700 with max_rows_to_read = 5000). Stack trace:
2019-07-12 17:55:17.856747: 
2019-07-12 17:55:17.856747: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:55:17.856747: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:55:17.856747: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:55:17.856747: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 17:55:17.856747: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 17:55:17.856747: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 17:55:17.856747: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 17:55:17.856747: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 17:55:17.856747: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 17:55:17.856747: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 17:55:17.856747: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 17:55:17.856747: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 17:55:17.856747: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 17:55:17.856747: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 17:55:17.856747: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 17:55:17.856747: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 17:55:17.856747: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:55:17.856747: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:55:17.856747: 18. clickhouse-server() [0x71eee5f]
2019-07-12 17:55:17.856747: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:55:17.856747: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:55:17.856747: 
2019-07-12 17:55:22.860437: Continuing after exception
2019-07-12 17:55:22.862598: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:55:34.541478: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 17:55:36.602069: Thread 140286829594368 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:55:52.926047: Iteration 8: 49.42
2019-07-12 17:56:41.077283: Iteration 9: 48.15
2019-07-12 17:56:42.586662: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 17:56:44.942579: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 17:57:22.601915: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:57:30.464088: Thread 140286829594368 encountered an exception:
2019-07-12 17:57:30.516781: Code: 241.
2019-07-12 17:57:30.516811: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 17:57:30.516811: 
2019-07-12 17:57:30.516811: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 17:57:30.516811: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 17:57:30.516811: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 17:57:30.516811: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 17:57:30.516811: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 17:57:30.516811: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 17:57:30.516811: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 17:57:30.516811: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 17:57:30.516811: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 17:57:30.516811: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 17:57:30.516811: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 17:57:30.516811: 11. clickhouse-server() [0x71eee5f]
2019-07-12 17:57:30.516811: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 17:57:30.516811: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 17:57:30.516811: 
2019-07-12 17:57:31.956242: Iteration 10: 50.88
2019-07-12 17:57:31.956705: 
2019-07-12 17:57:31.956721: Results for 1000000 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:57:31.957151: Actual rows fetched: 1000000
2019-07-12 17:57:31.957353: Time to execute select: 41.52 seconds
2019-07-12 17:57:31.957583: Time to put into dataframe: 7.72 seconds
2019-07-12 17:57:31.957726: Total time: 49.24 seconds
2019-07-12 17:57:31.958011: 
2019-07-12 17:57:31.958018: Current Query: Partition Key/Clustering Key Lookup: partitionhash = [190512000, 190512039] AND hashcode = [...]
2019-07-12 17:57:34.127974: Iteration 0: 2.17
2019-07-12 17:57:34.370241: Iteration 1: 0.24
2019-07-12 17:57:34.530863: Iteration 2: 0.16
2019-07-12 17:57:35.412627: Iteration 3: 0.88
2019-07-12 17:57:35.643377: Iteration 4: 0.23
2019-07-12 17:57:35.667035: Continuing after exception
2019-07-12 17:57:35.667616: Thread 140286829594368 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 17:57:36.010298: Iteration 5: 0.37
2019-07-12 17:57:36.816888: Iteration 6: 0.81
2019-07-12 17:57:37.113603: Iteration 7: 0.30
2019-07-12 17:57:37.543894: Iteration 8: 0.43
2019-07-12 17:57:37.721696: Iteration 9: 0.18
2019-07-12 17:57:37.999931: Iteration 10: 0.28
2019-07-12 17:57:38.001212: 
2019-07-12 17:57:38.001249: Results for 1 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:57:38.002122: Actual rows fetched: 1
2019-07-12 17:57:38.002492: Time to execute select: 0.44 seconds
2019-07-12 17:57:38.002879: Time to put into dataframe: 0.11 seconds
2019-07-12 17:57:38.003341: Total time: 0.55 seconds
2019-07-12 17:57:45.034275: Iteration 0: 7.03
2019-07-12 17:57:51.817465: Iteration 1: 6.78
2019-07-12 17:57:59.517149: Iteration 2: 7.70
2019-07-12 17:58:14.498085: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 17:58:39.932020: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 17:58:33.347389: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 17:58:58.998418: Iteration 3: 7.24
2019-07-12 17:59:06.932392: Iteration 4: 7.93
2019-07-12 17:59:14.402957: Iteration 5: 7.47
2019-07-12 17:59:21.492501: Iteration 6: 7.09
2019-07-12 17:59:29.477232: Iteration 7: 7.98
2019-07-12 17:59:36.469749: Iteration 8: 6.99
2019-07-12 17:59:43.790653: Iteration 9: 7.32
2019-07-12 17:59:51.038331: Iteration 10: 7.25
2019-07-12 17:59:51.039252: 
2019-07-12 17:59:51.039270: Results for 10 records averaged over 11 repetitions with schema type JSON:
2019-07-12 17:59:51.040091: Actual rows fetched: 10
2019-07-12 17:59:51.040601: Time to execute select: 7.33 seconds
2019-07-12 17:59:51.041109: Time to put into dataframe: 0.02 seconds
2019-07-12 17:59:51.041637: Total time: 7.34 seconds
2019-07-12 17:59:53.164294: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:00:09.158939: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:00:16.085615: Iteration 0: 25.04
2019-07-12 18:00:40.882475: Iteration 1: 24.80
2019-07-12 18:00:55.215231: Thread 140286838048512 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:01:05.719696: Iteration 2: 24.84
2019-07-12 18:01:30.085884: Iteration 3: 24.37
2019-07-12 18:01:53.363741: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:01:55.148633: Iteration 4: 25.06
2019-07-12 18:02:02.997615: Thread 140286526359296 encountered an exception:
2019-07-12 18:02:02.997773: Code: 241.
2019-07-12 18:02:02.997790: DB::Exception: Memory limit (for query) exceeded: would use 9.32 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:02:02.997790: 
2019-07-12 18:02:02.997790: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:02:02.997790: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:02:02.997790: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:02:02.997790: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:02:02.997790: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:02:02.997790: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:02:02.997790: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:02:02.997790: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:02:02.997790: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:02:02.997790: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:02:02.997790: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:02:02.997790: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:02:02.997790: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:02:02.997790: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:02:02.997790: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:02:02.997790: 
2019-07-12 18:02:08.002662: Continuing after exception
2019-07-12 18:02:08.004368: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:02:08.460791: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:02:13.008974: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:02:18.159613: Thread 140286526359296 encountered an exception:
2019-07-12 18:02:18.161158: Code: 241.
2019-07-12 18:02:18.161266: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:02:18.161266: 
2019-07-12 18:02:18.161266: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:02:18.161266: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:02:18.161266: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:02:18.161266: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:02:18.161266: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:02:18.161266: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:02:18.161266: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:02:18.161266: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:02:18.161266: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:02:18.161266: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:02:18.161266: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:02:18.161266: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:02:18.161266: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:02:18.161266: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:02:18.161266: 
2019-07-12 18:02:19.086531: Iteration 5: 23.94
2019-07-12 18:02:23.185219: Continuing after exception
2019-07-12 18:02:23.186974: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:02:33.246724: Thread 140286526359296 encountered an exception:
2019-07-12 18:02:33.247474: Code: 241.
2019-07-12 18:02:33.247588: DB::Exception: Memory limit (for query) exceeded: would use 9.43 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:02:33.247588: 
2019-07-12 18:02:33.247588: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:02:33.247588: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:02:33.247588: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:02:33.247588: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:02:33.247588: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:02:33.247588: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:02:33.247588: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:02:33.247588: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:02:33.247588: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:02:33.247588: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:02:33.247588: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:02:33.247588: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:02:33.247588: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:02:33.247588: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:02:33.247588: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:02:33.247588: 
2019-07-12 18:02:38.253169: Continuing after exception
2019-07-12 18:02:38.253822: Thread 140286526359296 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:02:41.736628: Iteration 6: 22.65
2019-07-12 18:03:00.192242: Thread 140286838048512 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:03:06.185264: Iteration 7: 24.45
2019-07-12 18:03:31.715250: Iteration 8: 25.53
2019-07-12 18:03:56.571037: Iteration 9: 24.85
2019-07-12 18:04:03.605788: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:04:08.075352: Thread 140286526359296 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:04:21.161238: Iteration 10: 24.59
2019-07-12 18:04:21.161842: 
2019-07-12 18:04:21.161853: Results for 100 records averaged over 11 repetitions with schema type JSON:
2019-07-12 18:04:21.162675: Actual rows fetched: 12
2019-07-12 18:04:21.162982: Time to execute select: 24.55 seconds
2019-07-12 18:04:21.163387: Time to put into dataframe: 0.01 seconds
2019-07-12 18:04:21.163795: Total time: 24.56 seconds
2019-07-12 18:04:21.164427: 
2019-07-12 18:04:21.164437: 
2019-07-12 18:04:21.164437: Current Schema: CH(NEW)
2019-07-12 18:04:21.169220: 
2019-07-12 18:04:21.169238: Current Query: Bulk Retrieval
2019-07-12 18:04:21.233143: Iteration 0: 0.06
2019-07-12 18:04:21.278864: Iteration 1: 0.04
2019-07-12 18:04:21.321672: Iteration 2: 0.04
2019-07-12 18:04:21.343215: Iteration 3: 0.02
2019-07-12 18:04:21.380993: Iteration 4: 0.04
2019-07-12 18:04:21.412794: Iteration 5: 0.03
2019-07-12 18:04:21.462179: Iteration 6: 0.05
2019-07-12 18:04:21.528644: Iteration 7: 0.07
2019-07-12 18:04:21.573143: Iteration 8: 0.04
2019-07-12 18:04:21.600367: Iteration 9: 0.03
2019-07-12 18:04:21.670933: Iteration 10: 0.07
2019-07-12 18:04:21.671585: 
2019-07-12 18:04:21.671604: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:04:21.672376: Actual rows fetched: 1
2019-07-12 18:04:21.672582: Time to execute select: 0.04 seconds
2019-07-12 18:04:21.672893: Time to put into dataframe: 0.01 seconds
2019-07-12 18:04:21.673298: Total time: 0.04 seconds
2019-07-12 18:04:21.715844: Iteration 0: 0.04
2019-07-12 18:04:21.771201: Iteration 1: 0.05
2019-07-12 18:04:21.808687: Iteration 2: 0.04
2019-07-12 18:04:21.840204: Iteration 3: 0.03
2019-07-12 18:04:21.872506: Iteration 4: 0.03
2019-07-12 18:04:21.934015: Iteration 5: 0.06
2019-07-12 18:04:21.971282: Iteration 6: 0.04
2019-07-12 18:04:22.003379: Iteration 7: 0.03
2019-07-12 18:04:22.034553: Iteration 8: 0.03
2019-07-12 18:04:22.079722: Iteration 9: 0.04
2019-07-12 18:04:22.151593: Iteration 10: 0.07
2019-07-12 18:04:22.152239: 
2019-07-12 18:04:22.152248: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:04:22.152807: Actual rows fetched: 10
2019-07-12 18:04:22.153189: Time to execute select: 0.04 seconds
2019-07-12 18:04:22.153340: Time to put into dataframe: 0.01 seconds
2019-07-12 18:04:22.153494: Total time: 0.04 seconds
2019-07-12 18:04:22.203695: Iteration 0: 0.05
2019-07-12 18:04:22.230192: Iteration 1: 0.03
2019-07-12 18:04:22.283514: Iteration 2: 0.05
2019-07-12 18:04:22.312957: Iteration 3: 0.03
2019-07-12 18:04:22.361335: Iteration 4: 0.05
2019-07-12 18:04:22.400744: Iteration 5: 0.04
2019-07-12 18:04:22.440756: Iteration 6: 0.04
2019-07-12 18:04:22.474769: Iteration 7: 0.03
2019-07-12 18:04:22.598798: Iteration 8: 0.12
2019-07-12 18:04:22.659918: Iteration 9: 0.06
2019-07-12 18:04:22.692297: Iteration 10: 0.03
2019-07-12 18:04:22.692859: 
2019-07-12 18:04:22.692868: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:04:22.693628: Actual rows fetched: 100
2019-07-12 18:04:22.693999: Time to execute select: 0.04 seconds
2019-07-12 18:04:22.694371: Time to put into dataframe: 0.00 seconds
2019-07-12 18:04:22.694756: Total time: 0.05 seconds
2019-07-12 18:04:22.796249: Iteration 0: 0.10
2019-07-12 18:04:22.879039: Iteration 1: 0.08
2019-07-12 18:04:22.941224: Iteration 2: 0.06
2019-07-12 18:04:23.008818: Iteration 3: 0.07
2019-07-12 18:04:23.082337: Iteration 4: 0.07
2019-07-12 18:04:23.159221: Iteration 5: 0.08
2019-07-12 18:04:23.261482: Iteration 6: 0.10
2019-07-12 18:04:23.336796: Iteration 7: 0.07
2019-07-12 18:04:23.437302: Iteration 8: 0.10
2019-07-12 18:04:23.509123: Iteration 9: 0.07
2019-07-12 18:04:23.576141: Iteration 10: 0.07
2019-07-12 18:04:23.576496: 
2019-07-12 18:04:23.576507: Results for 1000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:04:23.576736: Actual rows fetched: 1000
2019-07-12 18:04:23.576880: Time to execute select: 0.07 seconds
2019-07-12 18:04:23.576992: Time to put into dataframe: 0.01 seconds
2019-07-12 18:04:23.577090: Total time: 0.08 seconds
2019-07-12 18:04:24.074339: Iteration 0: 0.50
2019-07-12 18:04:24.610286: Iteration 1: 0.54
2019-07-12 18:04:25.157982: Iteration 2: 0.55
2019-07-12 18:04:25.644805: Iteration 3: 0.49
2019-07-12 18:04:26.179680: Iteration 4: 0.53
2019-07-12 18:04:26.710823: Iteration 5: 0.53
2019-07-12 18:04:27.238726: Iteration 6: 0.53
2019-07-12 18:04:27.755548: Iteration 7: 0.52
2019-07-12 18:04:28.301918: Iteration 8: 0.55
2019-07-12 18:04:28.849772: Iteration 9: 0.55
2019-07-12 18:04:29.393297: Iteration 10: 0.54
2019-07-12 18:04:29.393883: 
2019-07-12 18:04:29.393892: Results for 10000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:04:29.394609: Actual rows fetched: 10000
2019-07-12 18:04:29.394994: Time to execute select: 0.48 seconds
2019-07-12 18:04:29.395410: Time to put into dataframe: 0.05 seconds
2019-07-12 18:04:29.395823: Total time: 0.53 seconds
2019-07-12 18:04:33.708793: Iteration 0: 4.31
2019-07-12 18:04:38.114487: Iteration 1: 4.40
2019-07-12 18:04:42.509661: Iteration 2: 4.39
2019-07-12 18:04:46.965297: Iteration 3: 4.45
2019-07-12 18:04:51.479171: Iteration 4: 4.51
2019-07-12 18:04:55.948965: Iteration 5: 4.47
2019-07-12 18:05:00.277141: Iteration 6: 4.33
2019-07-12 18:05:04.975683: Iteration 7: 4.70
2019-07-12 18:05:09.566564: Iteration 8: 4.59
2019-07-12 18:05:14.115146: Iteration 9: 4.55
2019-07-12 18:05:18.541716: Iteration 10: 4.43
2019-07-12 18:05:18.542356: 
2019-07-12 18:05:18.542364: Results for 100000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:05:18.543095: Actual rows fetched: 100000
2019-07-12 18:05:18.543415: Time to execute select: 3.81 seconds
2019-07-12 18:05:18.543761: Time to put into dataframe: 0.66 seconds
2019-07-12 18:05:18.544062: Total time: 4.47 seconds
2019-07-12 18:05:20.324826: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:05:21.125610: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:06:05.642672: Iteration 0: 47.10
2019-07-12 18:06:53.475515: Iteration 1: 47.83
2019-07-12 18:06:55.439545: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:06:56.652025: Thread 140286526359296 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:06:59.301949: Thread 140286787585792 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:07:02.318139: Thread 140286829594368 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:07:10.241582: Thread 140286829594368 encountered an exception:
2019-07-12 18:07:10.253524: Code: 241.
2019-07-12 18:07:10.253551: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:07:10.253551: 
2019-07-12 18:07:10.253551: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:07:10.253551: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:07:10.253551: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:07:10.253551: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:07:10.253551: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:07:10.253551: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:07:10.253551: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:07:10.253551: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:07:10.253551: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:07:10.253551: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:07:10.253551: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:07:10.253551: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:07:10.253551: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:07:10.253551: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:07:10.253551: 
2019-07-12 18:07:15.259286: Continuing after exception
2019-07-12 18:07:15.261243: Thread 140286829594368 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:07:41.185180: Iteration 2: 47.71
2019-07-12 18:08:28.130389: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:08:33.440195: Iteration 3: 52.25
2019-07-12 18:08:34.675762: Thread 140286526359296 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:08:34.677122: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:08:57.420306: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:09:23.559047: Iteration 4: 50.12
2019-07-12 18:09:37.519281: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:10:03.689784: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:10:11.248081: Iteration 5: 47.69
2019-07-12 18:10:56.156751: Iteration 6: 44.91
2019-07-12 18:11:18.785061: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:11:40.575054: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:11:41.060926: Iteration 7: 44.90
2019-07-12 18:11:48.458026: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:12:07.968173: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:12:27.179696: Iteration 8: 46.12
2019-07-12 18:13:12.432788: Iteration 9: 45.25
2019-07-12 18:13:18.897354: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:14:01.277375: Iteration 10: 48.84
2019-07-12 18:14:01.277871: 
2019-07-12 18:14:01.277880: Results for 1000000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:01.278347: Actual rows fetched: 1000000
2019-07-12 18:14:01.278478: Time to execute select: 39.65 seconds
2019-07-12 18:14:01.278575: Time to put into dataframe: 7.87 seconds
2019-07-12 18:14:01.278744: Total time: 47.52 seconds
2019-07-12 18:14:01.278950: 
2019-07-12 18:14:01.278957: Current Query: Bulk Retreival: partitionhash = [-1000, -1]
2019-07-12 18:14:02.977399: Iteration 0: 1.70
2019-07-12 18:14:02.979306: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:14:03.042339: Iteration 1: 0.06
2019-07-12 18:14:03.110280: Iteration 2: 0.07
2019-07-12 18:14:03.166475: Iteration 3: 0.05
2019-07-12 18:14:03.220369: Iteration 4: 0.05
2019-07-12 18:14:03.247148: Iteration 5: 0.02
2019-07-12 18:14:03.293248: Iteration 6: 0.04
2019-07-12 18:14:03.324173: Iteration 7: 0.03
2019-07-12 18:14:03.361194: Iteration 8: 0.04
2019-07-12 18:14:03.390077: Iteration 9: 0.03
2019-07-12 18:14:03.443149: Iteration 10: 0.05
2019-07-12 18:14:03.444490: 
2019-07-12 18:14:03.444522: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:03.445972: Actual rows fetched: 0
2019-07-12 18:14:03.447038: Time to execute select: 0.12 seconds
2019-07-12 18:14:03.447640: Time to put into dataframe: 0.07 seconds
2019-07-12 18:14:03.448345: Total time: 0.20 seconds
2019-07-12 18:14:03.448938: 
2019-07-12 18:14:03.448971: Current Query: Bulk Retreival: carrierid = [18000, 19000]
2019-07-12 18:14:03.661959: Iteration 0: 0.21
2019-07-12 18:14:03.821945: Iteration 1: 0.16
2019-07-12 18:14:03.933083: Iteration 2: 0.11
2019-07-12 18:14:04.010206: Iteration 3: 0.08
2019-07-12 18:14:04.163688: Iteration 4: 0.15
2019-07-12 18:14:04.287149: Iteration 5: 0.12
2019-07-12 18:14:04.375657: Iteration 6: 0.09
2019-07-12 18:14:04.457421: Iteration 7: 0.08
2019-07-12 18:14:04.558992: Iteration 8: 0.10
2019-07-12 18:14:04.640400: Iteration 9: 0.08
2019-07-12 18:14:04.770539: Iteration 10: 0.13
2019-07-12 18:14:04.771250: 
2019-07-12 18:14:04.771272: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:04.772130: Actual rows fetched: 1
2019-07-12 18:14:04.772486: Time to execute select: 0.10 seconds
2019-07-12 18:14:04.772996: Time to put into dataframe: 0.01 seconds
2019-07-12 18:14:04.773365: Total time: 0.12 seconds
2019-07-12 18:14:04.885376: Iteration 0: 0.11
2019-07-12 18:14:05.021836: Iteration 1: 0.14
2019-07-12 18:14:05.118746: Iteration 2: 0.10
2019-07-12 18:14:05.218579: Iteration 3: 0.10
2019-07-12 18:14:05.358049: Iteration 4: 0.14
2019-07-12 18:14:05.429073: Iteration 5: 0.07
2019-07-12 18:14:05.536343: Iteration 6: 0.11
2019-07-12 18:14:05.640722: Iteration 7: 0.10
2019-07-12 18:14:05.759506: Iteration 8: 0.12
2019-07-12 18:14:05.862047: Iteration 9: 0.10
2019-07-12 18:14:05.938392: Iteration 10: 0.08
2019-07-12 18:14:05.939435: 
2019-07-12 18:14:05.939457: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:05.940408: Actual rows fetched: 10
2019-07-12 18:14:05.940927: Time to execute select: 0.09 seconds
2019-07-12 18:14:05.941533: Time to put into dataframe: 0.01 seconds
2019-07-12 18:14:05.942086: Total time: 0.10 seconds
2019-07-12 18:14:06.073668: Iteration 0: 0.13
2019-07-12 18:14:06.174688: Iteration 1: 0.10
2019-07-12 18:14:06.270216: Iteration 2: 0.09
2019-07-12 18:14:06.372870: Iteration 3: 0.10
2019-07-12 18:14:06.460634: Iteration 4: 0.09
2019-07-12 18:14:06.567781: Iteration 5: 0.11
2019-07-12 18:14:06.693897: Iteration 6: 0.13
2019-07-12 18:14:06.772733: Iteration 7: 0.08
2019-07-12 18:14:06.847667: Iteration 8: 0.07
2019-07-12 18:14:06.909473: Iteration 9: 0.06
2019-07-12 18:14:07.013741: Iteration 10: 0.10
2019-07-12 18:14:07.014400: 
2019-07-12 18:14:07.014415: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:07.015252: Actual rows fetched: 100
2019-07-12 18:14:07.015690: Time to execute select: 0.09 seconds
2019-07-12 18:14:07.015947: Time to put into dataframe: 0.01 seconds
2019-07-12 18:14:07.016416: Total time: 0.10 seconds
2019-07-12 18:14:07.154270: Iteration 0: 0.14
2019-07-12 18:14:07.281833: Iteration 1: 0.13
2019-07-12 18:14:07.488655: Iteration 2: 0.21
2019-07-12 18:14:07.588819: Iteration 3: 0.10
2019-07-12 18:14:07.700301: Iteration 4: 0.11
2019-07-12 18:14:07.922612: Iteration 5: 0.22
2019-07-12 18:14:08.081651: Iteration 6: 0.16
2019-07-12 18:14:08.198251: Iteration 7: 0.12
2019-07-12 18:14:08.365578: Iteration 8: 0.17
2019-07-12 18:14:08.506247: Iteration 9: 0.14
2019-07-12 18:14:08.656492: Iteration 10: 0.15
2019-07-12 18:14:08.657034: 
2019-07-12 18:14:08.657043: Results for 1000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:08.657767: Actual rows fetched: 1000
2019-07-12 18:14:08.658166: Time to execute select: 0.14 seconds
2019-07-12 18:14:08.658555: Time to put into dataframe: 0.01 seconds
2019-07-12 18:14:08.658997: Total time: 0.15 seconds
2019-07-12 18:14:09.176508: Iteration 0: 0.52
2019-07-12 18:14:09.726457: Iteration 1: 0.55
2019-07-12 18:14:10.169921: Iteration 2: 0.44
2019-07-12 18:14:10.649136: Iteration 3: 0.48
2019-07-12 18:14:11.150889: Iteration 4: 0.50
2019-07-12 18:14:11.681578: Iteration 5: 0.53
2019-07-12 18:14:12.144914: Iteration 6: 0.46
2019-07-12 18:14:12.646057: Iteration 7: 0.50
2019-07-12 18:14:13.114675: Iteration 8: 0.47
2019-07-12 18:14:13.568014: Iteration 9: 0.45
2019-07-12 18:14:14.096771: Iteration 10: 0.53
2019-07-12 18:14:14.097207: 
2019-07-12 18:14:14.097214: Results for 10000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:14.097508: Actual rows fetched: 10000
2019-07-12 18:14:14.097642: Time to execute select: 0.44 seconds
2019-07-12 18:14:14.097770: Time to put into dataframe: 0.05 seconds
2019-07-12 18:14:14.097923: Total time: 0.49 seconds
2019-07-12 18:14:18.696791: Iteration 0: 4.60
2019-07-12 18:14:23.272531: Iteration 1: 4.58
2019-07-12 18:14:27.448447: Iteration 2: 4.18
2019-07-12 18:14:31.754264: Iteration 3: 4.31
2019-07-12 18:14:36.067346: Iteration 4: 4.31
2019-07-12 18:14:36.526130: Iteration 5: 0.46
2019-07-12 18:14:40.930525: Iteration 6: 4.40
2019-07-12 18:14:45.253767: Iteration 7: 4.32
2019-07-12 18:14:49.583661: Iteration 8: 4.33
2019-07-12 18:14:52.913954: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:14:53.712073: Iteration 9: 4.13
2019-07-12 18:14:58.028735: Iteration 10: 4.32
2019-07-12 18:14:58.029158: 
2019-07-12 18:14:58.029169: Results for 100000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:14:58.029423: Actual rows fetched: 100000
2019-07-12 18:14:58.029625: Time to execute select: 3.36 seconds
2019-07-12 18:14:58.029807: Time to put into dataframe: 0.63 seconds
2019-07-12 18:14:58.030055: Total time: 3.99 seconds
2019-07-12 18:14:58.030306: 
2019-07-12 18:14:58.030314: Current Query: Bulk Retreival: partitionhash <= [190512000, 190512039]
2019-07-12 18:14:58.296606: Iteration 0: 0.27
2019-07-12 18:14:58.499227: Iteration 1: 0.20
2019-07-12 18:14:58.682024: Iteration 2: 0.18
2019-07-12 18:14:58.895873: Iteration 3: 0.19
2019-07-12 18:14:59.065171: Iteration 4: 0.17
2019-07-12 18:14:59.257240: Iteration 5: 0.19
2019-07-12 18:14:59.468591: Iteration 6: 0.21
2019-07-12 18:14:59.653100: Iteration 7: 0.18
2019-07-12 18:14:59.829517: Iteration 8: 0.18
2019-07-12 18:15:00.027896: Iteration 9: 0.20
2019-07-12 18:15:00.184025: Iteration 10: 0.16
2019-07-12 18:15:00.184577: 
2019-07-12 18:15:00.184589: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:15:00.185056: Actual rows fetched: 1
2019-07-12 18:15:00.185230: Time to execute select: 0.18 seconds
2019-07-12 18:15:00.185409: Time to put into dataframe: 0.02 seconds
2019-07-12 18:15:00.185624: Total time: 0.19 seconds
2019-07-12 18:15:00.336459: Iteration 0: 0.15
2019-07-12 18:15:00.642289: Iteration 1: 0.30
2019-07-12 18:15:00.816716: Iteration 2: 0.17
2019-07-12 18:15:01.023230: Iteration 3: 0.21
2019-07-12 18:15:01.204736: Iteration 4: 0.18
2019-07-12 18:15:01.398833: Iteration 5: 0.19
2019-07-12 18:15:01.579951: Iteration 6: 0.18
2019-07-12 18:15:01.790766: Iteration 7: 0.21
2019-07-12 18:15:01.951682: Iteration 8: 0.16
2019-07-12 18:15:02.157393: Iteration 9: 0.20
2019-07-12 18:15:02.332898: Iteration 10: 0.17
2019-07-12 18:15:02.333927: 
2019-07-12 18:15:02.333951: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:15:02.335177: Actual rows fetched: 10
2019-07-12 18:15:02.335674: Time to execute select: 0.18 seconds
2019-07-12 18:15:02.336143: Time to put into dataframe: 0.02 seconds
2019-07-12 18:15:02.336629: Total time: 0.19 seconds
2019-07-12 18:15:02.510712: Iteration 0: 0.17
2019-07-12 18:15:02.685167: Iteration 1: 0.17
2019-07-12 18:15:02.850931: Iteration 2: 0.17
2019-07-12 18:15:03.105211: Iteration 3: 0.25
2019-07-12 18:15:03.329781: Iteration 4: 0.22
2019-07-12 18:15:03.545417: Iteration 5: 0.21
2019-07-12 18:15:03.723182: Iteration 6: 0.18
2019-07-12 18:15:03.939395: Iteration 7: 0.22
2019-07-12 18:15:04.123424: Iteration 8: 0.18
2019-07-12 18:15:04.292535: Iteration 9: 0.17
2019-07-12 18:15:04.465495: Iteration 10: 0.17
2019-07-12 18:15:04.466582: 
2019-07-12 18:15:04.466607: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:15:04.467941: Actual rows fetched: 100
2019-07-12 18:15:04.468545: Time to execute select: 0.18 seconds
2019-07-12 18:15:04.469029: Time to put into dataframe: 0.01 seconds
2019-07-12 18:15:04.469546: Total time: 0.19 seconds
2019-07-12 18:15:04.707694: Iteration 0: 0.24
2019-07-12 18:15:04.862661: Iteration 1: 0.15
2019-07-12 18:15:05.052871: Iteration 2: 0.19
2019-07-12 18:15:05.250890: Iteration 3: 0.20
2019-07-12 18:15:05.489629: Iteration 4: 0.24
2019-07-12 18:15:05.694701: Iteration 5: 0.20
2019-07-12 18:15:05.879294: Iteration 6: 0.18
2019-07-12 18:15:06.056471: Iteration 7: 0.18
2019-07-12 18:15:06.265101: Iteration 8: 0.21
2019-07-12 18:15:06.475294: Iteration 9: 0.21
2019-07-12 18:15:06.654350: Iteration 10: 0.18
2019-07-12 18:15:06.654811: 
2019-07-12 18:15:06.654819: Results for 1000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:15:06.655231: Actual rows fetched: 1000
2019-07-12 18:15:06.655440: Time to execute select: 0.19 seconds
2019-07-12 18:15:06.655583: Time to put into dataframe: 0.01 seconds
2019-07-12 18:15:06.655787: Total time: 0.20 seconds
2019-07-12 18:15:07.170403: Iteration 0: 0.51
2019-07-12 18:15:07.705997: Iteration 1: 0.54
2019-07-12 18:15:08.235813: Iteration 2: 0.53
2019-07-12 18:15:08.705322: Iteration 3: 0.47
2019-07-12 18:15:09.193111: Iteration 4: 0.49
2019-07-12 18:15:09.716103: Iteration 5: 0.52
2019-07-12 18:15:10.240161: Iteration 6: 0.52
2019-07-12 18:15:10.794529: Iteration 7: 0.55
2019-07-12 18:15:11.305843: Iteration 8: 0.51
2019-07-12 18:15:11.822200: Iteration 9: 0.52
2019-07-12 18:15:12.306641: Iteration 10: 0.48
2019-07-12 18:15:12.307154: 
2019-07-12 18:15:12.307162: Results for 10000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:15:12.307537: Actual rows fetched: 10000
2019-07-12 18:15:12.307739: Time to execute select: 0.46 seconds
2019-07-12 18:15:12.307943: Time to put into dataframe: 0.05 seconds
2019-07-12 18:15:12.308111: Total time: 0.51 seconds
2019-07-12 18:15:16.625581: Iteration 0: 4.32
2019-07-12 18:15:20.904065: Iteration 1: 4.28
2019-07-12 18:15:25.352894: Iteration 2: 4.45
2019-07-12 18:15:29.842110: Iteration 3: 4.49
2019-07-12 18:15:33.776579: Thread 140286526359296 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:15:34.189495: Iteration 4: 4.35
2019-07-12 18:15:38.774586: Iteration 5: 4.58
2019-07-12 18:15:41.426858: Thread 140286829594368 encountered an exception:
2019-07-12 18:15:41.436389: Code: 241.
2019-07-12 18:15:41.436422: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 2048 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:15:41.436422: 
2019-07-12 18:15:41.436422: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:15:41.436422: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:15:41.436422: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:15:41.436422: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:15:41.436422: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:15:41.436422: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:15:41.436422: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:15:41.436422: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:15:41.436422: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:15:41.436422: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:15:41.436422: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:15:41.436422: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:15:41.436422: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:15:41.436422: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:15:41.436422: 
2019-07-12 18:15:43.059896: Iteration 6: 4.28
2019-07-12 18:15:44.199005: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:15:46.459883: Continuing after exception
2019-07-12 18:15:46.471818: Thread 140286829594368 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:15:47.395623: Iteration 7: 4.34
2019-07-12 18:15:52.019652: Iteration 8: 4.62
2019-07-12 18:15:54.517502: Thread 140286787585792 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:15:57.119255: Iteration 9: 5.10
2019-07-12 18:16:01.583121: Iteration 10: 4.46
2019-07-12 18:16:01.583714: 
2019-07-12 18:16:01.583722: Results for 100000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:16:01.584393: Actual rows fetched: 100000
2019-07-12 18:16:01.584786: Time to execute select: 3.78 seconds
2019-07-12 18:16:01.585182: Time to put into dataframe: 0.70 seconds
2019-07-12 18:16:01.585577: Total time: 4.48 seconds
2019-07-12 18:16:05.839644: Thread 140286787585792 encountered an exception:
2019-07-12 18:16:05.857580: Code: 241.
2019-07-12 18:16:05.857655: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:16:05.857655: 
2019-07-12 18:16:05.857655: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:16:05.857655: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:16:05.857655: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:16:05.857655: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:16:05.857655: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:16:05.857655: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:16:05.857655: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:16:05.857655: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:16:05.857655: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:16:05.857655: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:16:05.857655: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:16:05.857655: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:16:05.857655: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:16:05.857655: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:16:05.857655: 
2019-07-12 18:16:10.868220: Continuing after exception
2019-07-12 18:16:10.870674: Thread 140286787585792 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:16:45.337526: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:16:46.446051: Iteration 0: 44.86
2019-07-12 18:17:33.414654: Iteration 1: 46.97
2019-07-12 18:17:40.800216: Thread 140286787585792 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:18:21.086923: Iteration 2: 47.67
2019-07-12 18:18:30.460720: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:18:31.057425: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:18:38.942061: Thread 140286526359296 encountered an exception:
2019-07-12 18:18:38.953945: Code: 241.
2019-07-12 18:18:38.953974: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:18:38.953974: 
2019-07-12 18:18:38.953974: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:18:38.953974: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:18:38.953974: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:18:38.953974: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:18:38.953974: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:18:38.953974: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:18:38.953974: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:18:38.953974: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:18:38.953974: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:18:38.953974: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:18:38.953974: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:18:38.953974: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:18:38.953974: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:18:38.953974: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:18:38.953974: 
2019-07-12 18:18:43.972742: Continuing after exception
2019-07-12 18:18:43.984920: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:18:52.905684: Thread 140286526359296 encountered an exception:
2019-07-12 18:18:52.906217: Code: 241.
2019-07-12 18:18:52.906232: DB::Exception: Memory limit (for query) exceeded: would use 9.41 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:18:52.906232: 
2019-07-12 18:18:52.906232: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:18:52.906232: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:18:52.906232: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:18:52.906232: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:18:52.906232: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:18:52.906232: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:18:52.906232: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:18:52.906232: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:18:52.906232: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:18:52.906232: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:18:52.906232: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:18:52.906232: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:18:52.906232: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:18:52.906232: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:18:52.906232: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:18:52.906232: 
2019-07-12 18:18:57.931224: Continuing after exception
2019-07-12 18:18:57.943203: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:19:06.614385: Iteration 3: 45.53
2019-07-12 18:19:06.615051: Thread 140286526359296 encountered an exception:
2019-07-12 18:19:06.615322: Code: 241.
2019-07-12 18:19:06.615336: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:19:06.615336: 
2019-07-12 18:19:06.615336: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:19:06.615336: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:19:06.615336: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:19:06.615336: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:19:06.615336: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:19:06.615336: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:19:06.615336: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:19:06.615336: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:19:06.615336: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:19:06.615336: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:19:06.615336: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:19:06.615336: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:19:06.615336: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:19:06.615336: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:19:06.615336: 
2019-07-12 18:19:11.620184: Continuing after exception
2019-07-12 18:19:11.638563: Thread 140286526359296 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:19:17.716243: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:19:20.696092: Thread 140286526359296 encountered an exception:
2019-07-12 18:19:20.707489: Code: 241.
2019-07-12 18:19:20.707510: DB::Exception: Memory limit (for query) exceeded: would use 9.34 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:19:20.707510: 
2019-07-12 18:19:20.707510: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:19:20.707510: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:19:20.707510: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:19:20.707510: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:19:20.707510: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:19:20.707510: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:19:20.707510: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:19:20.707510: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:19:20.707510: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:19:20.707510: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:19:20.707510: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:19:20.707510: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:19:20.707510: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:19:20.707510: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:19:20.707510: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:19:20.707510: 
2019-07-12 18:19:22.033343: Thread 140286829594368 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:19:25.742247: Continuing after exception
2019-07-12 18:19:25.746715: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:19:25.843028: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:19:51.183950: Iteration 4: 44.57
2019-07-12 18:20:44.911090: Iteration 5: 53.73
2019-07-12 18:21:01.597291: Thread 140286787585792 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:21:06.511070: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:21:06.685423: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:21:33.249217: Iteration 6: 48.34
2019-07-12 18:22:11.978351: Thread 140286838048512 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:22:21.949669: Iteration 7: 48.70
2019-07-12 18:22:31.744480: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:22:58.227260: Thread 140286838048512 encountered an exception:
2019-07-12 18:22:58.245093: Code: 241.
2019-07-12 18:22:58.245123: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 12320 with max_rows_to_read = 5000). Stack trace:
2019-07-12 18:22:58.245123: 
2019-07-12 18:22:58.245123: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:22:58.245123: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:22:58.245123: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:22:58.245123: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:22:58.245123: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 18:22:58.245123: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 18:22:58.245123: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 18:22:58.245123: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 18:22:58.245123: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 18:22:58.245123: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 18:22:58.245123: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 18:22:58.245123: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 18:22:58.245123: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:22:58.245123: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 18:22:58.245123: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:22:58.245123: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 18:22:58.245123: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:22:58.245123: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:22:58.245123: 18. clickhouse-server() [0x71eee5f]
2019-07-12 18:22:58.245123: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:22:58.245123: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:22:58.245123: 
2019-07-12 18:23:03.691635: Continuing after exception
2019-07-12 18:23:04.316061: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:23:04.316159: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:23:09.344331: Iteration 8: 47.39
2019-07-12 18:23:58.271849: Iteration 9: 48.93
2019-07-12 18:24:07.788954: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:24:36.480930: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:24:43.187881: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:24:47.311942: Iteration 10: 49.04
2019-07-12 18:24:47.312504: 
2019-07-12 18:24:47.312512: Results for 1000000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:24:47.312975: Actual rows fetched: 1000000
2019-07-12 18:24:47.313152: Time to execute select: 40.18 seconds
2019-07-12 18:24:47.313328: Time to put into dataframe: 7.61 seconds
2019-07-12 18:24:47.313556: Total time: 47.79 seconds
2019-07-12 18:24:47.313673: 
2019-07-12 18:24:47.313683: Current Query: Bulk Retreival: subscriptionid >= [11111, 11611] AND subscriptionid <= [11111, 11611]
2019-07-12 18:24:49.357240: Iteration 0: 2.04
2019-07-12 18:24:49.584527: Iteration 1: 0.23
2019-07-12 18:24:49.723327: Iteration 2: 0.14
2019-07-12 18:24:49.881845: Iteration 3: 0.16
2019-07-12 18:24:50.117673: Iteration 4: 0.24
2019-07-12 18:24:50.274525: Iteration 5: 0.16
2019-07-12 18:24:50.417176: Iteration 6: 0.14
2019-07-12 18:24:50.580193: Iteration 7: 0.16
2019-07-12 18:24:50.716610: Iteration 8: 0.14
2019-07-12 18:24:50.928800: Iteration 9: 0.21
2019-07-12 18:24:51.158799: Iteration 10: 0.23
2019-07-12 18:24:51.159388: 
2019-07-12 18:24:51.159397: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:24:51.160153: Actual rows fetched: 1
2019-07-12 18:24:51.160323: Time to execute select: 0.27 seconds
2019-07-12 18:24:51.160514: Time to put into dataframe: 0.08 seconds
2019-07-12 18:24:51.160710: Total time: 0.35 seconds
2019-07-12 18:24:51.305928: Iteration 0: 0.14
2019-07-12 18:24:51.674102: Iteration 1: 0.37
2019-07-12 18:24:51.859999: Iteration 2: 0.19
2019-07-12 18:24:52.081619: Iteration 3: 0.22
2019-07-12 18:24:52.228633: Iteration 4: 0.15
2019-07-12 18:24:52.326120: Iteration 5: 0.10
2019-07-12 18:24:52.486801: Iteration 6: 0.16
2019-07-12 18:24:52.630578: Iteration 7: 0.14
2019-07-12 18:24:52.805915: Iteration 8: 0.17
2019-07-12 18:24:52.950964: Iteration 9: 0.14
2019-07-12 18:24:53.083499: Iteration 10: 0.13
2019-07-12 18:24:53.083928: 
2019-07-12 18:24:53.083937: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:24:53.084404: Actual rows fetched: 10
2019-07-12 18:24:53.084586: Time to execute select: 0.17 seconds
2019-07-12 18:24:53.084804: Time to put into dataframe: 0.00 seconds
2019-07-12 18:24:53.085022: Total time: 0.17 seconds
2019-07-12 18:24:53.221991: Iteration 0: 0.14
2019-07-12 18:24:53.375932: Iteration 1: 0.15
2019-07-12 18:24:53.542477: Iteration 2: 0.17
2019-07-12 18:24:53.692761: Iteration 3: 0.15
2019-07-12 18:24:53.901599: Iteration 4: 0.21
2019-07-12 18:24:54.042331: Iteration 5: 0.14
2019-07-12 18:24:54.163414: Iteration 6: 0.12
2019-07-12 18:24:54.320437: Iteration 7: 0.16
2019-07-12 18:24:54.489227: Iteration 8: 0.17
2019-07-12 18:24:54.632482: Iteration 9: 0.14
2019-07-12 18:24:54.830882: Iteration 10: 0.20
2019-07-12 18:24:54.831418: 
2019-07-12 18:24:54.831433: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:24:54.831758: Actual rows fetched: 100
2019-07-12 18:24:54.831945: Time to execute select: 0.15 seconds
2019-07-12 18:24:54.832122: Time to put into dataframe: 0.01 seconds
2019-07-12 18:24:54.832303: Total time: 0.16 seconds
2019-07-12 18:24:55.026188: Iteration 0: 0.19
2019-07-12 18:24:55.304017: Iteration 1: 0.28
2019-07-12 18:24:55.434275: Iteration 2: 0.13
2019-07-12 18:24:55.636520: Iteration 3: 0.20
2019-07-12 18:24:55.802738: Iteration 4: 0.17
2019-07-12 18:24:56.005387: Iteration 5: 0.20
2019-07-12 18:24:56.235034: Iteration 6: 0.23
2019-07-12 18:24:56.407692: Iteration 7: 0.17
2019-07-12 18:24:56.600640: Iteration 8: 0.19
2019-07-12 18:24:56.769348: Iteration 9: 0.17
2019-07-12 18:24:56.986099: Iteration 10: 0.22
2019-07-12 18:24:56.986615: 
2019-07-12 18:24:56.986623: Results for 1000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:24:56.987197: Actual rows fetched: 1000
2019-07-12 18:24:56.987584: Time to execute select: 0.18 seconds
2019-07-12 18:24:56.987919: Time to put into dataframe: 0.02 seconds
2019-07-12 18:24:56.988291: Total time: 0.20 seconds
2019-07-12 18:24:57.557410: Iteration 0: 0.57
2019-07-12 18:24:58.167534: Iteration 1: 0.61
2019-07-12 18:24:58.772214: Iteration 2: 0.60
2019-07-12 18:24:59.256664: Iteration 3: 0.48
2019-07-12 18:24:59.751613: Iteration 4: 0.49
2019-07-12 18:25:00.280342: Iteration 5: 0.53
2019-07-12 18:25:00.809404: Iteration 6: 0.53
2019-07-12 18:25:01.334468: Iteration 7: 0.52
2019-07-12 18:25:01.858401: Iteration 8: 0.52
2019-07-12 18:25:02.446594: Iteration 9: 0.59
2019-07-12 18:25:02.952314: Iteration 10: 0.51
2019-07-12 18:25:02.952743: 
2019-07-12 18:25:02.952751: Results for 10000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:25:02.953090: Actual rows fetched: 10000
2019-07-12 18:25:02.953201: Time to execute select: 0.48 seconds
2019-07-12 18:25:02.953327: Time to put into dataframe: 0.06 seconds
2019-07-12 18:25:02.953457: Total time: 0.54 seconds
2019-07-12 18:25:08.072845: Iteration 0: 5.12
2019-07-12 18:25:13.302257: Iteration 1: 5.23
2019-07-12 18:25:13.359805: Thread 140286787585792 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:25:17.992299: Iteration 2: 4.69
2019-07-12 18:25:21.353140: Thread 140286787585792 encountered an exception:
2019-07-12 18:25:21.359735: Code: 241.
2019-07-12 18:25:21.359756: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:25:21.359756: 
2019-07-12 18:25:21.359756: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:25:21.359756: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:25:21.359756: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:25:21.359756: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:25:21.359756: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:25:21.359756: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:25:21.359756: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:25:21.359756: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:25:21.359756: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:25:21.359756: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:25:21.359756: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:25:21.359756: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:25:21.359756: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:25:21.359756: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:25:21.359756: 
2019-07-12 18:25:22.887456: Iteration 3: 4.89
2019-07-12 18:25:26.386890: Continuing after exception
2019-07-12 18:25:26.398870: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:25:27.500082: Iteration 4: 4.61
2019-07-12 18:25:32.102961: Iteration 5: 4.60
2019-07-12 18:25:36.560894: Iteration 6: 4.46
2019-07-12 18:25:41.148574: Iteration 7: 4.59
2019-07-12 18:25:45.725875: Iteration 8: 4.58
2019-07-12 18:25:47.118406: Thread 140286526359296 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:25:50.578705: Iteration 9: 4.85
2019-07-12 18:25:51.866816: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:25:55.090007: Iteration 10: 4.51
2019-07-12 18:25:55.090501: 
2019-07-12 18:25:55.090509: Results for 100000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:25:55.090849: Actual rows fetched: 100000
2019-07-12 18:25:55.091021: Time to execute select: 4.07 seconds
2019-07-12 18:25:55.091213: Time to put into dataframe: 0.67 seconds
2019-07-12 18:25:55.091375: Total time: 4.74 seconds
2019-07-12 18:26:15.443508: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:26:42.618671: Iteration 0: 47.53
2019-07-12 18:26:56.376334: Thread 140286838048512 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:27:03.408680: Thread 140286829594368 encountered an exception:
2019-07-12 18:27:03.426048: Code: 241.
2019-07-12 18:27:03.426070: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 8192 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:27:03.426070: 
2019-07-12 18:27:03.426070: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:27:03.426070: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:27:03.426070: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:27:03.426070: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:27:03.426070: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:27:03.426070: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:27:03.426070: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:27:03.426070: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:27:03.426070: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:27:03.426070: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:27:03.426070: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:27:03.426070: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:27:03.426070: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:27:03.426070: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:27:03.426070: 
2019-07-12 18:27:04.299171: Thread 140286787585792 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:27:08.453023: Continuing after exception
2019-07-12 18:27:08.465022: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:27:27.718602: Thread 140286526359296 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:27:33.479311: Iteration 1: 50.86
2019-07-12 18:28:09.253255: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:28:21.939984: Iteration 2: 48.46
2019-07-12 18:28:38.085990: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:28:42.166962: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:28:56.883909: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:29:09.695297: Iteration 3: 47.75
2019-07-12 18:29:48.979265: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:29:58.724342: Iteration 4: 49.03
2019-07-12 18:30:00.571718: Thread 140286526359296 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:30:16.940469: Thread 140286829594368 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:30:46.085097: Iteration 5: 47.36
2019-07-12 18:31:13.278591: Thread 140286526359296 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:31:25.730112: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:31:29.706587: Thread 140286829594368 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:31:33.812473: Thread 140286838048512 encountered an exception:
2019-07-12 18:31:34.291766: Iteration 6: 48.21
2019-07-12 18:31:34.292101: Code: 241.
2019-07-12 18:31:34.292126: DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:31:34.292126: 
2019-07-12 18:31:34.292126: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:31:34.292126: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:31:34.292126: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:31:34.292126: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:31:34.292126: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:31:34.292126: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:31:34.292126: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:31:34.292126: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:31:34.292126: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:31:34.292126: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:31:34.292126: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:31:34.292126: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:31:34.292126: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:31:34.292126: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:31:34.292126: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:31:34.292126: 
2019-07-12 18:31:39.299782: Continuing after exception
2019-07-12 18:31:39.308083: Thread 140286838048512 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:32:15.221738: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:32:19.028387: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:32:20.729290: Iteration 7: 46.44
2019-07-12 18:32:32.320705: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:32:51.981620: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:33:05.689212: Thread 140286787585792 encountered an exception:
2019-07-12 18:33:05.842045: Code: 241.
2019-07-12 18:33:05.842069: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 92451 with max_rows_to_read = 5000). Stack trace:
2019-07-12 18:33:05.842069: 
2019-07-12 18:33:05.842069: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:33:05.842069: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:33:05.842069: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:33:05.842069: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:33:05.842069: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 18:33:05.842069: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 18:33:05.842069: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 18:33:05.842069: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 18:33:05.842069: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 18:33:05.842069: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 18:33:05.842069: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 18:33:05.842069: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 18:33:05.842069: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:33:05.842069: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 18:33:05.842069: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:33:05.842069: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 18:33:05.842069: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:33:05.842069: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:33:05.842069: 18. clickhouse-server() [0x71eee5f]
2019-07-12 18:33:05.842069: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:33:05.842069: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:33:05.842069: 
2019-07-12 18:33:07.569270: Iteration 8: 46.84
2019-07-12 18:33:11.056792: Continuing after exception
2019-07-12 18:33:11.068794: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:33:54.345645: Iteration 9: 46.78
2019-07-12 18:34:01.436747: Thread 140286526359296 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:34:32.987164: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:34:39.556283: Iteration 10: 45.21
2019-07-12 18:34:39.557008: 
2019-07-12 18:34:39.557034: Results for 1000000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:34:39.557309: Actual rows fetched: 1000000
2019-07-12 18:34:39.557442: Time to execute select: 39.99 seconds
2019-07-12 18:34:39.557569: Time to put into dataframe: 7.69 seconds
2019-07-12 18:34:39.557683: Total time: 47.68 seconds
2019-07-12 18:34:39.557909: 
2019-07-12 18:34:39.557931: Current Query: Bulk Retreival: partitionhash = [190512000, 190512039] AND subscriptionid >= [11111, 11611] AND subscriptionid <= [11111, 11611]
2019-07-12 18:34:41.307368: Iteration 0: 1.75
2019-07-12 18:34:41.428503: Iteration 1: 0.12
2019-07-12 18:34:41.611131: Iteration 2: 0.18
2019-07-12 18:34:41.781333: Iteration 3: 0.17
2019-07-12 18:34:41.927079: Iteration 4: 0.15
2019-07-12 18:34:42.061789: Iteration 5: 0.13
2019-07-12 18:34:42.229065: Iteration 6: 0.17
2019-07-12 18:34:42.360414: Iteration 7: 0.13
2019-07-12 18:34:42.486943: Iteration 8: 0.13
2019-07-12 18:34:42.633400: Iteration 9: 0.15
2019-07-12 18:34:42.837911: Iteration 10: 0.20
2019-07-12 18:34:42.838482: 
2019-07-12 18:34:42.838493: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:34:42.839276: Actual rows fetched: 1
2019-07-12 18:34:42.839625: Time to execute select: 0.21 seconds
2019-07-12 18:34:42.839811: Time to put into dataframe: 0.09 seconds
2019-07-12 18:34:42.840015: Total time: 0.30 seconds
2019-07-12 18:34:42.996688: Iteration 0: 0.16
2019-07-12 18:34:43.112030: Iteration 1: 0.11
2019-07-12 18:34:43.237160: Iteration 2: 0.12
2019-07-12 18:34:43.382030: Iteration 3: 0.14
2019-07-12 18:34:43.577639: Iteration 4: 0.19
2019-07-12 18:34:43.731786: Iteration 5: 0.15
2019-07-12 18:34:43.895206: Iteration 6: 0.16
2019-07-12 18:34:44.066653: Iteration 7: 0.17
2019-07-12 18:34:44.252487: Iteration 8: 0.18
2019-07-12 18:34:44.407830: Iteration 9: 0.15
2019-07-12 18:34:44.578548: Iteration 10: 0.17
2019-07-12 18:34:44.579513: 
2019-07-12 18:34:44.579536: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:34:44.580512: Actual rows fetched: 10
2019-07-12 18:34:44.580805: Time to execute select: 0.14 seconds
2019-07-12 18:34:44.581294: Time to put into dataframe: 0.02 seconds
2019-07-12 18:34:44.581740: Total time: 0.16 seconds
2019-07-12 18:34:44.759998: Iteration 0: 0.18
2019-07-12 18:34:44.953772: Iteration 1: 0.19
2019-07-12 18:34:45.125085: Iteration 2: 0.17
2019-07-12 18:34:45.288447: Iteration 3: 0.16
2019-07-12 18:34:45.474897: Iteration 4: 0.19
2019-07-12 18:34:45.671752: Iteration 5: 0.20
2019-07-12 18:34:45.882966: Iteration 6: 0.21
2019-07-12 18:34:46.062428: Iteration 7: 0.18
2019-07-12 18:34:46.209787: Iteration 8: 0.15
2019-07-12 18:34:46.375722: Iteration 9: 0.17
2019-07-12 18:34:46.574841: Iteration 10: 0.20
2019-07-12 18:34:46.575847: 
2019-07-12 18:34:46.575871: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:34:46.577017: Actual rows fetched: 100
2019-07-12 18:34:46.577574: Time to execute select: 0.17 seconds
2019-07-12 18:34:46.578138: Time to put into dataframe: 0.01 seconds
2019-07-12 18:34:46.578729: Total time: 0.18 seconds
2019-07-12 18:34:46.814367: Iteration 0: 0.23
2019-07-12 18:34:47.052017: Iteration 1: 0.24
2019-07-12 18:34:47.193915: Iteration 2: 0.14
2019-07-12 18:34:47.379550: Iteration 3: 0.18
2019-07-12 18:34:47.591841: Iteration 4: 0.21
2019-07-12 18:34:47.723855: Iteration 5: 0.13
2019-07-12 18:34:47.920337: Iteration 6: 0.20
2019-07-12 18:34:48.122308: Iteration 7: 0.20
2019-07-12 18:34:48.319127: Iteration 8: 0.20
2019-07-12 18:34:48.456762: Iteration 9: 0.14
2019-07-12 18:34:48.614627: Iteration 10: 0.16
2019-07-12 18:34:48.615173: 
2019-07-12 18:34:48.615182: Results for 1000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:34:48.615955: Actual rows fetched: 1000
2019-07-12 18:34:48.616315: Time to execute select: 0.17 seconds
2019-07-12 18:34:48.616699: Time to put into dataframe: 0.01 seconds
2019-07-12 18:34:48.617041: Total time: 0.18 seconds
2019-07-12 18:34:49.131665: Iteration 0: 0.51
2019-07-12 18:34:49.580638: Iteration 1: 0.45
2019-07-12 18:34:50.084075: Iteration 2: 0.50
2019-07-12 18:34:50.622494: Iteration 3: 0.54
2019-07-12 18:34:51.139934: Iteration 4: 0.52
2019-07-12 18:34:51.694170: Iteration 5: 0.55
2019-07-12 18:34:52.185488: Iteration 6: 0.49
2019-07-12 18:34:52.679874: Iteration 7: 0.49
2019-07-12 18:34:53.188521: Iteration 8: 0.51
2019-07-12 18:34:53.650478: Iteration 9: 0.46
2019-07-12 18:34:54.133608: Iteration 10: 0.48
2019-07-12 18:34:54.134207: 
2019-07-12 18:34:54.134217: Results for 10000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:34:54.134953: Actual rows fetched: 10000
2019-07-12 18:34:54.135289: Time to execute select: 0.45 seconds
2019-07-12 18:34:54.135679: Time to put into dataframe: 0.05 seconds
2019-07-12 18:34:54.136065: Total time: 0.50 seconds
2019-07-12 18:34:55.551752: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:34:58.571966: Iteration 0: 4.44
2019-07-12 18:35:02.896039: Iteration 1: 4.32
2019-07-12 18:35:06.963891: Iteration 2: 4.07
2019-07-12 18:35:11.142921: Iteration 3: 4.18
2019-07-12 18:35:15.296211: Thread 140286829594368 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:35:15.427621: Iteration 4: 4.28
2019-07-12 18:35:19.749205: Iteration 5: 4.32
2019-07-12 18:35:24.498321: Iteration 6: 4.75
2019-07-12 18:35:29.187393: Iteration 7: 4.69
2019-07-12 18:35:33.765447: Iteration 8: 4.58
2019-07-12 18:35:38.167513: Iteration 9: 4.40
2019-07-12 18:35:42.752488: Iteration 10: 4.58
2019-07-12 18:35:42.752638: Thread 140286787585792 encountered an exception:
2019-07-12 18:35:42.753101: 
2019-07-12 18:35:42.753109: Results for 100000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:35:42.754178: Actual rows fetched: 100000
2019-07-12 18:35:42.753281: Code: 241.
2019-07-12 18:35:42.753316: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1024 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:35:42.753316: 
2019-07-12 18:35:42.753316: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:35:42.753316: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:35:42.753316: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:35:42.753316: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:35:42.753316: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:35:42.753316: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:35:42.753316: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:35:42.753316: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:35:42.753316: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:35:42.753316: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:35:42.753316: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:35:42.753316: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:35:42.753316: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:35:42.753316: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:35:42.753316: 
2019-07-12 18:35:42.757665: Time to execute select: 3.73 seconds
2019-07-12 18:35:42.757847: Time to put into dataframe: 0.69 seconds
2019-07-12 18:35:42.757954: Total time: 4.42 seconds
2019-07-12 18:35:46.071172: Thread 140286526359296 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:35:47.758534: Continuing after exception
2019-07-12 18:35:47.776458: Thread 140286787585792 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:36:12.459133: Iteration 0: 29.70
2019-07-12 18:36:17.351023: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:36:18.380534: Thread 140286829594368 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:36:26.577240: Thread 140286838048512 encountered an exception:
2019-07-12 18:36:26.589241: Code: 241.
2019-07-12 18:36:26.589284: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:36:26.589284: 
2019-07-12 18:36:26.589284: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:36:26.589284: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:36:26.589284: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:36:26.589284: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:36:26.589284: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:36:26.589284: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:36:26.589284: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:36:26.589284: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:36:26.589284: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:36:26.589284: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:36:26.589284: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:36:26.589284: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:36:26.589284: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:36:26.589284: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:36:26.589284: 
2019-07-12 18:36:27.689028: Thread 140286829594368 encountered an exception:
2019-07-12 18:36:27.712079: Code: 241.
2019-07-12 18:36:27.712113: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:36:27.712113: 
2019-07-12 18:36:27.712113: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:36:27.712113: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:36:27.712113: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:36:27.712113: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:36:27.712113: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:36:27.712113: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:36:27.712113: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:36:27.712113: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:36:27.712113: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:36:27.712113: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:36:27.712113: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:36:27.712113: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:36:27.712113: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:36:27.712113: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:36:27.712113: 
2019-07-12 18:36:31.610087: Continuing after exception
2019-07-12 18:36:31.612405: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:36:32.751180: Continuing after exception
2019-07-12 18:36:32.763141: Thread 140286829594368 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:36:52.098000: Iteration 1: 39.64
2019-07-12 18:37:20.514344: Thread 140286829594368 encountered an exception:
2019-07-12 18:37:20.526254: Code: 241.
2019-07-12 18:37:20.526291: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201901_4645169_4721667_232/ from mark 30351 with max_rows_to_read = 5000). Stack trace:
2019-07-12 18:37:20.526291: 
2019-07-12 18:37:20.526291: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:37:20.526291: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:37:20.526291: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:37:20.526291: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:37:20.526291: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 18:37:20.526291: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 18:37:20.526291: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 18:37:20.526291: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 18:37:20.526291: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 18:37:20.526291: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 18:37:20.526291: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 18:37:20.526291: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 18:37:20.526291: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:37:20.526291: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 18:37:20.526291: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:37:20.526291: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 18:37:20.526291: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:37:20.526291: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:37:20.526291: 18. clickhouse-server() [0x71eee5f]
2019-07-12 18:37:20.526291: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:37:20.526291: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:37:20.526291: 
2019-07-12 18:37:23.486522: Thread 140286787585792 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:37:25.535434: Continuing after exception
2019-07-12 18:37:25.548269: Thread 140286829594368 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:37:31.337714: Thread 140286787585792 encountered an exception:
2019-07-12 18:37:31.400426: Code: 241.
2019-07-12 18:37:31.400450: DB::Exception: Memory limit (for query) exceeded: would use 9.42 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:37:31.400450: 
2019-07-12 18:37:31.400450: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:37:31.400450: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:37:31.400450: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:37:31.400450: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:37:31.400450: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:37:31.400450: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:37:31.400450: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:37:31.400450: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:37:31.400450: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:37:31.400450: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:37:31.400450: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:37:31.400450: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:37:31.400450: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:37:31.400450: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:37:31.400450: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:37:31.400450: 
2019-07-12 18:37:33.490679: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:37:35.074788: Iteration 2: 42.98
2019-07-12 18:37:36.469749: Continuing after exception
2019-07-12 18:37:36.476639: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:38:22.029800: Iteration 3: 46.95
2019-07-12 18:38:25.419227: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:38:26.401040: Thread 140286829594368 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:38:55.768869: Iteration 4: 33.74
2019-07-12 18:39:41.866714: Iteration 5: 46.10
2019-07-12 18:40:16.176025: Iteration 6: 34.31
2019-07-12 18:40:18.788694: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:40:26.839822: Thread 140286838048512 encountered an exception:
2019-07-12 18:40:26.840515: Code: 241.
2019-07-12 18:40:26.840544: DB::Exception: Memory limit (for query) exceeded: would use 9.36 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:40:26.840544: 
2019-07-12 18:40:26.840544: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:40:26.840544: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:40:26.840544: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:40:26.840544: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:40:26.840544: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:40:26.840544: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:40:26.840544: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:40:26.840544: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:40:26.840544: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:40:26.840544: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:40:26.840544: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:40:26.840544: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:40:26.840544: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:40:26.840544: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:40:26.840544: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:40:26.840544: 
2019-07-12 18:40:31.849190: Continuing after exception
2019-07-12 18:40:31.861067: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:41:02.984793: Iteration 7: 46.81
2019-07-12 18:41:20.108318: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:41:47.073494: Iteration 8: 44.09
2019-07-12 18:42:05.039018: Thread 140286829594368 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:42:10.495792: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:42:11.200578: Thread 140286838048512 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:42:24.043848: Iteration 9: 36.97
2019-07-12 18:42:56.310864: Thread 140286526359296 encountered an exception:
2019-07-12 18:42:56.322730: Code: 241.
2019-07-12 18:42:56.322760: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 128 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:42:56.322760: 
2019-07-12 18:42:56.322760: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:42:56.322760: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:42:56.322760: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:42:56.322760: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:42:56.322760: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:42:56.322760: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:42:56.322760: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:42:56.322760: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:42:56.322760: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:42:56.322760: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:42:56.322760: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:42:56.322760: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:42:56.322760: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:42:56.322760: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:42:56.322760: 
2019-07-12 18:43:01.345358: Continuing after exception
2019-07-12 18:43:01.357349: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:43:04.087377: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:43:09.919548: Iteration 10: 45.87
2019-07-12 18:43:09.920073: 
2019-07-12 18:43:09.920085: Results for 1000000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:43:09.920645: Actual rows fetched: 1000000
2019-07-12 18:43:09.920868: Time to execute select: 34.00 seconds
2019-07-12 18:43:09.921201: Time to put into dataframe: 6.65 seconds
2019-07-12 18:43:09.921346: Total time: 40.65 seconds
2019-07-12 18:43:09.921517: 
2019-07-12 18:43:09.921525: Current Query: Partition Key Lookup: partitionhash = [190512000, 190512039]
2019-07-12 18:43:11.560894: Iteration 0: 1.64
2019-07-12 18:43:11.794963: Iteration 1: 0.23
2019-07-12 18:43:11.947534: Iteration 2: 0.15
2019-07-12 18:43:12.138065: Iteration 3: 0.19
2019-07-12 18:43:12.295059: Iteration 4: 0.16
2019-07-12 18:43:12.506447: Iteration 5: 0.21
2019-07-12 18:43:12.960976: Iteration 6: 0.45
2019-07-12 18:43:13.149966: Iteration 7: 0.19
2019-07-12 18:43:13.313466: Iteration 8: 0.16
2019-07-12 18:43:13.545234: Iteration 9: 0.23
2019-07-12 18:43:13.722966: Iteration 10: 0.18
2019-07-12 18:43:13.723882: 
2019-07-12 18:43:13.723899: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:43:13.724853: Actual rows fetched: 1
2019-07-12 18:43:13.725348: Time to execute select: 0.26 seconds
2019-07-12 18:43:13.725839: Time to put into dataframe: 0.08 seconds
2019-07-12 18:43:13.726323: Total time: 0.34 seconds
2019-07-12 18:43:13.985098: Iteration 0: 0.26
2019-07-12 18:43:14.277979: Iteration 1: 0.29
2019-07-12 18:43:14.492539: Iteration 2: 0.21
2019-07-12 18:43:14.682426: Iteration 3: 0.19
2019-07-12 18:43:14.836502: Iteration 4: 0.15
2019-07-12 18:43:15.051184: Iteration 5: 0.21
2019-07-12 18:43:15.237304: Iteration 6: 0.19
2019-07-12 18:43:15.421456: Iteration 7: 0.18
2019-07-12 18:43:15.631627: Iteration 8: 0.21
2019-07-12 18:43:15.946970: Iteration 9: 0.31
2019-07-12 18:43:16.168298: Iteration 10: 0.22
2019-07-12 18:43:16.169116: 
2019-07-12 18:43:16.169133: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:43:16.170221: Actual rows fetched: 10
2019-07-12 18:43:16.170617: Time to execute select: 0.20 seconds
2019-07-12 18:43:16.171123: Time to put into dataframe: 0.02 seconds
2019-07-12 18:43:16.171611: Total time: 0.22 seconds
2019-07-12 18:43:16.640124: Iteration 0: 0.47
2019-07-12 18:43:16.843397: Iteration 1: 0.20
2019-07-12 18:43:17.092473: Iteration 2: 0.25
2019-07-12 18:43:17.283291: Iteration 3: 0.19
2019-07-12 18:43:17.440229: Iteration 4: 0.16
2019-07-12 18:43:17.609124: Iteration 5: 0.17
2019-07-12 18:43:17.747732: Iteration 6: 0.14
2019-07-12 18:43:17.882723: Iteration 7: 0.13
2019-07-12 18:43:18.069043: Iteration 8: 0.19
2019-07-12 18:43:18.248468: Iteration 9: 0.18
2019-07-12 18:43:18.395123: Iteration 10: 0.15
2019-07-12 18:43:18.395738: 
2019-07-12 18:43:18.395754: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:43:18.396624: Actual rows fetched: 100
2019-07-12 18:43:18.397088: Time to execute select: 0.19 seconds
2019-07-12 18:43:18.398142: Time to put into dataframe: 0.01 seconds
2019-07-12 18:43:18.398753: Total time: 0.20 seconds
2019-07-12 18:43:18.626517: Iteration 0: 0.23
2019-07-12 18:43:18.858673: Iteration 1: 0.23
2019-07-12 18:43:19.105693: Iteration 2: 0.25
2019-07-12 18:43:19.250370: Iteration 3: 0.14
2019-07-12 18:43:19.434628: Iteration 4: 0.18
2019-07-12 18:43:19.570115: Iteration 5: 0.13
2019-07-12 18:43:19.763666: Iteration 6: 0.19
2019-07-12 18:43:19.931868: Iteration 7: 0.17
2019-07-12 18:43:20.067683: Iteration 8: 0.14
2019-07-12 18:43:20.252305: Iteration 9: 0.18
2019-07-12 18:43:20.447818: Iteration 10: 0.19
2019-07-12 18:43:20.448297: 
2019-07-12 18:43:20.448306: Results for 1000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:43:20.449078: Actual rows fetched: 1000
2019-07-12 18:43:20.449465: Time to execute select: 0.17 seconds
2019-07-12 18:43:20.449857: Time to put into dataframe: 0.01 seconds
2019-07-12 18:43:20.450236: Total time: 0.19 seconds
2019-07-12 18:43:20.940781: Iteration 0: 0.49
2019-07-12 18:43:21.582113: Iteration 1: 0.64
2019-07-12 18:43:22.099168: Iteration 2: 0.52
2019-07-12 18:43:22.626569: Iteration 3: 0.53
2019-07-12 18:43:23.101154: Iteration 4: 0.47
2019-07-12 18:43:23.658771: Iteration 5: 0.56
2019-07-12 18:43:24.203062: Iteration 6: 0.54
2019-07-12 18:43:24.789775: Iteration 7: 0.59
2019-07-12 18:43:25.343756: Iteration 8: 0.55
2019-07-12 18:43:25.979121: Iteration 9: 0.63
2019-07-12 18:43:26.560946: Iteration 10: 0.58
2019-07-12 18:43:26.561203: 
2019-07-12 18:43:26.561214: Results for 10000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:43:26.561907: Actual rows fetched: 10000
2019-07-12 18:43:26.562056: Time to execute select: 0.50 seconds
2019-07-12 18:43:26.562199: Time to put into dataframe: 0.05 seconds
2019-07-12 18:43:26.562342: Total time: 0.55 seconds
2019-07-12 18:43:31.532171: Iteration 0: 4.97
2019-07-12 18:43:33.652707: Thread 140286829594368 starting background query: select tcp_flags,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags,icmp_type order by connections desc limit 50
2019-07-12 18:43:36.452871: Iteration 1: 4.92
2019-07-12 18:43:41.204573: Iteration 2: 4.75
2019-07-12 18:43:45.857621: Iteration 3: 4.65
2019-07-12 18:43:50.783556: Iteration 4: 4.93
2019-07-12 18:43:50.783841: Thread 140286838048512 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:43:53.368602: Thread 140286787585792 encountered an exception:
2019-07-12 18:43:53.376744: Code: 241.
2019-07-12 18:43:53.376768: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_4602466_4648029_9/ from mark 36205 with max_rows_to_read = 5000). Stack trace:
2019-07-12 18:43:53.376768: 
2019-07-12 18:43:53.376768: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:43:53.376768: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:43:53.376768: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:43:53.376768: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:43:53.376768: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 18:43:53.376768: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 18:43:53.376768: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 18:43:53.376768: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 18:43:53.376768: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 18:43:53.376768: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 18:43:53.376768: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 18:43:53.376768: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 18:43:53.376768: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:43:53.376768: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 18:43:53.376768: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:43:53.376768: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 18:43:53.376768: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:43:53.376768: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:43:53.376768: 18. clickhouse-server() [0x71eee5f]
2019-07-12 18:43:53.376768: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:43:53.376768: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:43:53.376768: 
2019-07-12 18:43:55.899983: Iteration 5: 5.12
2019-07-12 18:43:58.380199: Continuing after exception
2019-07-12 18:43:58.381394: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:44:00.680564: Iteration 6: 4.78
2019-07-12 18:44:05.036771: Iteration 7: 4.36
2019-07-12 18:44:10.671812: Iteration 8: 5.63
2019-07-12 18:44:15.304058: Iteration 9: 4.63
2019-07-12 18:44:19.897056: Iteration 10: 4.59
2019-07-12 18:44:19.897523: 
2019-07-12 18:44:19.897532: Results for 100000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:44:19.897974: Actual rows fetched: 100000
2019-07-12 18:44:19.898198: Time to execute select: 4.16 seconds
2019-07-12 18:44:19.898403: Time to put into dataframe: 0.69 seconds
2019-07-12 18:44:19.898646: Total time: 4.85 seconds
2019-07-12 18:44:45.210914: Thread 140286787585792 encountered an exception:
2019-07-12 18:44:45.214589: Code: 241.
2019-07-12 18:44:45.214614: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:44:45.214614: 
2019-07-12 18:44:45.214614: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:44:45.214614: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:44:45.214614: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:44:45.214614: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:44:45.214614: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:44:45.214614: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:44:45.214614: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:44:45.214614: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:44:45.214614: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:44:45.214614: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:44:45.214614: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:44:45.214614: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:44:45.214614: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:44:45.214614: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:44:45.214614: 
2019-07-12 18:44:50.217937: Continuing after exception
2019-07-12 18:44:50.219118: Thread 140286787585792 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:45:03.348313: Thread 140286838048512 starting background query: select direction,forwarding_statusstatus,icmp_type,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by direction,forwarding_statusstatus,icmp_type order by connections desc limit 50
2019-07-12 18:45:07.023480: Iteration 0: 47.12
2019-07-12 18:45:10.803763: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:45:38.250737: Thread 140286787585792 encountered an exception:
2019-07-12 18:45:38.263184: Code: 241.
2019-07-12 18:45:38.263236: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 4096 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:45:38.263236: 
2019-07-12 18:45:38.263236: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:45:38.263236: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:45:38.263236: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:45:38.263236: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:45:38.263236: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:45:38.263236: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:45:38.263236: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:45:38.263236: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:45:38.263236: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:45:38.263236: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:45:38.263236: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:45:38.263236: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:45:38.263236: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:45:38.263236: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:45:38.263236: 
2019-07-12 18:45:43.281466: Continuing after exception
2019-07-12 18:45:43.294458: Thread 140286787585792 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:45:54.936377: Iteration 1: 47.91
2019-07-12 18:46:33.288034: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:46:40.729824: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:46:41.369124: Iteration 2: 46.43
2019-07-12 18:46:41.369488: Thread 140286838048512 encountered an exception:
2019-07-12 18:46:41.369922: Code: 241.
2019-07-12 18:46:41.369938: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:46:41.369938: 
2019-07-12 18:46:41.369938: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:46:41.369938: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:46:41.369938: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:46:41.369938: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:46:41.369938: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:46:41.369938: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:46:41.369938: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:46:41.369938: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:46:41.369938: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:46:41.369938: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:46:41.369938: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:46:41.369938: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:46:41.369938: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:46:41.369938: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:46:41.369938: 
2019-07-12 18:46:46.378546: Continuing after exception
2019-07-12 18:46:46.397848: Thread 140286838048512 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:46:49.300037: Thread 140286829594368 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:46:58.053110: Thread 140286829594368 encountered an exception:
2019-07-12 18:46:58.064837: Code: 241.
2019-07-12 18:46:58.064859: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:46:58.064859: 
2019-07-12 18:46:58.064859: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:46:58.064859: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:46:58.064859: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:46:58.064859: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:46:58.064859: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:46:58.064859: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:46:58.064859: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:46:58.064859: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:46:58.064859: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:46:58.064859: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:46:58.064859: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:46:58.064859: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:46:58.064859: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:46:58.064859: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:46:58.064859: 
2019-07-12 18:47:03.089433: Continuing after exception
2019-07-12 18:47:03.101428: Thread 140286829594368 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:47:11.928315: Thread 140286829594368 encountered an exception:
2019-07-12 18:47:11.935285: Code: 241.
2019-07-12 18:47:11.935306: DB::Exception: Memory limit (for query) exceeded: would use 9.37 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:47:11.935306: 
2019-07-12 18:47:11.935306: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:47:11.935306: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:47:11.935306: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:47:11.935306: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:47:11.935306: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:47:11.935306: 5. clickhouse-server(DB::ColumnString::serializeValueIntoArena(unsigned long, DB::Arena&, char const*&) const+0x93) [0x5ebec23]
2019-07-12 18:47:11.935306: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x88) [0x627a2e8]
2019-07-12 18:47:11.935306: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:47:11.935306: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:47:11.935306: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:47:11.935306: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:47:11.935306: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:47:11.935306: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:47:11.935306: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:47:11.935306: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:47:11.935306: 
2019-07-12 18:47:16.963387: Continuing after exception
2019-07-12 18:47:16.975457: Thread 140286829594368 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:47:18.519342: Thread 140286787585792 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:47:29.519665: Iteration 3: 48.15
2019-07-12 18:47:29.520442: Thread 140286526359296 encountered an exception:
2019-07-12 18:47:29.520753: Code: 241.
2019-07-12 18:47:29.520768: DB::Exception: Memory limit (for query) exceeded: would use 9.40 GiB (attempt to allocate chunk of 134217728 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:47:29.520768: 
2019-07-12 18:47:29.520768: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:47:29.520768: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:47:29.520768: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:47:29.520768: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:47:29.520768: 4. clickhouse-server(DB::Arena::addChunk(unsigned long)+0x89) [0x31e4289]
2019-07-12 18:47:29.520768: 5. clickhouse-server(DB::Arena::alignedAlloc(unsigned long, unsigned long)+0x3b) [0x57cf0cb]
2019-07-12 18:47:29.520768: 6. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x29b) [0x627a4fb]
2019-07-12 18:47:29.520768: 7. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:47:29.520768: 8. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:47:29.520768: 9. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:47:29.520768: 10. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:47:29.520768: 11. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:47:29.520768: 12. clickhouse-server() [0x71eee5f]
2019-07-12 18:47:29.520768: 13. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:47:29.520768: 14. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:47:29.520768: 
2019-07-12 18:47:34.522676: Continuing after exception
2019-07-12 18:47:34.523335: Thread 140286526359296 starting background query: select out_src_mac,tcp_flags,out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac,tcp_flags,out_src_mac order by connections desc limit 50
2019-07-12 18:49:12.295340: Iteration 4: 102.77
2019-07-12 18:49:25.898810: Thread 140286838048512 starting background query: select in_bytes,ipv4_next_hop,last_switched,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_bytes,ipv4_next_hop,last_switched order by connections desc limit 50
2019-07-12 18:49:33.973138: Thread 140286838048512 encountered an exception:
2019-07-12 18:49:33.975771: Code: 241.
2019-07-12 18:49:33.975804: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 1572864 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:49:33.975804: 
2019-07-12 18:49:33.975804: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:49:33.975804: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:49:33.975804: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:49:33.975804: 3. clickhouse-server(Allocator<true>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a26d3]
2019-07-12 18:49:33.975804: 4. clickhouse-server(HashTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true> >::resize(unsigned long, unsigned long)+0x74) [0x62790d4]
2019-07-12 18:49:33.975804: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x33c) [0x627a59c]
2019-07-12 18:49:33.975804: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:49:33.975804: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:49:33.975804: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:49:33.975804: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:49:33.975804: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:49:33.975804: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:49:33.975804: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:49:33.975804: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:49:33.975804: 
2019-07-12 18:49:38.981531: Continuing after exception
2019-07-12 18:49:38.982167: Thread 140286838048512 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:50:00.172313: Thread 140286829594368 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:50:04.176078: Iteration 5: 51.88
2019-07-12 18:50:21.952282: Thread 140286526359296 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:50:43.561477: Thread 140286838048512 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:50:56.511294: Iteration 6: 52.33
2019-07-12 18:50:58.682473: Thread 140286787585792 starting background query: select flowset_id,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by flowset_id order by connections desc limit 50
2019-07-12 18:51:09.050682: Thread 140286526359296 encountered an exception:
2019-07-12 18:51:09.053545: Code: 241.
2019-07-12 18:51:09.053571: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 65536 bytes), maximum: 9.31 GiB: (while reading column protocolname): (while reading from part /ClikHausData/data_root/data/netflow/netflow_raw/201812_1_4602465_734/ from mark 113635 with max_rows_to_read = 5000). Stack trace:
2019-07-12 18:51:09.053571: 
2019-07-12 18:51:09.053571: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:51:09.053571: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:51:09.053571: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:51:09.053571: 3. clickhouse-server(Allocator<false>::alloc(unsigned long, unsigned long)+0x22) [0x66a29b2]
2019-07-12 18:51:09.053571: 4. clickhouse-server(DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const+0x2ed) [0x5cdfa9d]
2019-07-12 18:51:09.053571: 5. clickhouse-server(DB::MergeTreeReader::readData(std::string const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool)+0x2ea) [0x637406a]
2019-07-12 18:51:09.053571: 6. clickhouse-server(DB::MergeTreeReader::readRows(unsigned long, bool, unsigned long, DB::Block&)+0x2f3) [0x6374703]
2019-07-12 18:51:09.053571: 7. clickhouse-server(DB::MergeTreeRangeReader::DelayedStream::finalize(DB::Block&)+0x13e) [0x63702ee]
2019-07-12 18:51:09.053571: 8. clickhouse-server(DB::MergeTreeRangeReader::startReadingChain(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x19f) [0x6370fff]
2019-07-12 18:51:09.053571: 9. clickhouse-server(DB::MergeTreeRangeReader::read(unsigned long, std::vector<DB::MarkRange, std::allocator<DB::MarkRange> >&)+0x622) [0x6372792]
2019-07-12 18:51:09.053571: 10. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readFromPart()+0x7d0) [0x6363c00]
2019-07-12 18:51:09.053571: 11. clickhouse-server(DB::MergeTreeBaseSelectBlockInputStream::readImpl()+0xa3) [0x6365113]
2019-07-12 18:51:09.053571: 12. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:51:09.053571: 13. clickhouse-server(DB::ExpressionBlockInputStream::readImpl()+0x1a) [0x61ae2ba]
2019-07-12 18:51:09.053571: 14. clickhouse-server(DB::IBlockInputStream::read()+0x135) [0x5c44675]
2019-07-12 18:51:09.053571: 15. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x2b5) [0x61da335]
2019-07-12 18:51:09.053571: 16. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:51:09.053571: 17. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:51:09.053571: 18. clickhouse-server() [0x71eee5f]
2019-07-12 18:51:09.053571: 19. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:51:09.053571: 20. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:51:09.053571: 
2019-07-12 18:51:14.080442: Continuing after exception
2019-07-12 18:51:14.081663: Thread 140286526359296 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:51:29.904670: Thread 140286838048512 encountered an exception:
2019-07-12 18:51:29.916995: Code: 241.
2019-07-12 18:51:29.917048: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 256 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:51:29.917048: 
2019-07-12 18:51:29.917048: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:51:29.917048: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:51:29.917048: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:51:29.917048: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:51:29.917048: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:51:29.917048: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:51:29.917048: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:51:29.917048: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:51:29.917048: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:51:29.917048: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:51:29.917048: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:51:29.917048: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:51:29.917048: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:51:29.917048: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:51:29.917048: 
2019-07-12 18:51:34.943158: Continuing after exception
2019-07-12 18:51:34.957931: Thread 140286838048512 starting background query: select protocolname,ipv4_src_addr,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by protocolname,ipv4_src_addr order by connections desc limit 50
2019-07-12 18:51:47.454297: Iteration 7: 50.94
2019-07-12 18:52:02.086336: Thread 140286787585792 starting background query: select tcp_flags,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by tcp_flags order by connections desc limit 50
2019-07-12 18:52:23.220823: Thread 140286838048512 encountered an exception:
2019-07-12 18:52:23.221264: Code: 241.
2019-07-12 18:52:23.221282: DB::Exception: Memory limit (for query) exceeded: would use 9.31 GiB (attempt to allocate chunk of 512 bytes), maximum: 9.31 GiB. Stack trace:
2019-07-12 18:52:23.221282: 
2019-07-12 18:52:23.221282: 0. clickhouse-server(StackTrace::StackTrace()+0x16) [0x66bee66]
2019-07-12 18:52:23.221282: 1. clickhouse-server(MemoryTracker::alloc(long)+0x799) [0x66b7fc9]
2019-07-12 18:52:23.221282: 2. clickhouse-server(MemoryTracker::alloc(long)+0xa8) [0x66b78d8]
2019-07-12 18:52:23.221282: 3. clickhouse-server(Allocator<false>::realloc(void*, unsigned long, unsigned long, unsigned long)+0xb3) [0x66a3043]
2019-07-12 18:52:23.221282: 4. clickhouse-server(ReservoirSampler<int, (ReservoirSamplerOnEmpty::Enum)1, std::less<int> >::insert(int const&)+0x145) [0x5944785]
2019-07-12 18:52:23.221282: 5. clickhouse-server(void DB::Aggregator::executeImplCase<false, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >::State&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, char*) const+0x1d8) [0x627a438]
2019-07-12 18:52:23.221282: 6. clickhouse-server(void DB::Aggregator::executeImpl<DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> > >(DB::AggregationMethodSerialized<TwoLevelHashMapTable<StringRef, HashMapCellWithSavedHash<StringRef, char*, DefaultHash<StringRef>, HashTableNoState>, DefaultHash<StringRef>, TwoLevelHashTableGrower<8ul>, Allocator<true>, HashMapTable> >&, DB::Arena*, unsigned long, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, DB::Aggregator::AggregateFunctionInstruction*, std::vector<StringRef, std::allocator<StringRef> >&, bool, char*) const+0x154) [0x627a804]
2019-07-12 18:52:23.221282: 7. clickhouse-server(DB::Aggregator::executeOnBlock(DB::Block const&, DB::AggregatedDataVariants&, std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >&, std::vector<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> >, std::allocator<std::vector<DB::IColumn const*, std::allocator<DB::IColumn const*> > > >&, std::vector<StringRef, std::allocator<StringRef> >&, bool&)+0x18d7) [0x62264f7]
2019-07-12 18:52:23.221282: 8. clickhouse-server(DB::ParallelInputsProcessor<DB::ParallelAggregatingBlockInputStream::Handler>::thread(std::shared_ptr<DB::ThreadGroupStatus>, unsigned long)+0x3ba) [0x61da43a]
2019-07-12 18:52:23.221282: 9. clickhouse-server(_ZZN20ThreadFromGlobalPoolC4IZN2DB23ParallelInputsProcessorINS1_35ParallelAggregatingBlockInputStream7HandlerEE7processEvEUlvE_JEEEOT_DpOT0_ENKUlvE_clEv+0x5d) [0x61dab7d]
2019-07-12 18:52:23.221282: 10. clickhouse-server(ThreadPoolImpl<std::thread>::worker(std::_List_iterator<std::thread>)+0x187) [0x66c4bb7]
2019-07-12 18:52:23.221282: 11. clickhouse-server() [0x71eee5f]
2019-07-12 18:52:23.221282: 12. /lib64/libpthread.so.0(+0x7dd5) [0x7f717e4b6dd5]
2019-07-12 18:52:23.221282: 13. /lib64/libc.so.6(clone+0x6d) [0x7f717d7b8ead]
2019-07-12 18:52:23.221282: 
2019-07-12 18:52:28.848325: Continuing after exception
2019-07-12 18:52:29.286544: Thread 140286838048512 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:52:35.576137: Iteration 8: 48.12
2019-07-12 18:53:13.557436: Thread 140286787585792 starting background query: select in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by in_dst_mac order by connections desc limit 50
2019-07-12 18:53:23.511474: Iteration 9: 47.93
2019-07-12 18:53:35.549091: Thread 140286829594368 starting background query: select out_src_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by out_src_mac order by connections desc limit 50
2019-07-12 18:54:10.891405: Iteration 10: 47.38
2019-07-12 18:54:10.892029: 
2019-07-12 18:54:10.892053: Results for 1000000 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:54:10.892276: Actual rows fetched: 1000000
2019-07-12 18:54:10.892404: Time to execute select: 46.07 seconds
2019-07-12 18:54:10.892530: Time to put into dataframe: 7.66 seconds
2019-07-12 18:54:10.892665: Total time: 53.73 seconds
2019-07-12 18:54:10.892788: 
2019-07-12 18:54:10.892797: Current Query: Partition Key/Clustering Key Lookup: partitionhash = [190512000, 190512039] AND hashcode = [...]
2019-07-12 18:54:12.625114: Iteration 0: 1.73
2019-07-12 18:54:12.627225: Thread 140286838048512 starting background query: select dst_mask,ipv4_next_hop,in_dst_mac,count(*) as connections,sum(in_pkts),avg(in_pkts),quantiles(.25,.5,.75)(in_pkts),median(in_pkts) from netflow.netflow_raw group by dst_mask,ipv4_next_hop,in_dst_mac order by connections desc limit 50
2019-07-12 18:54:12.720242: Iteration 1: 0.09
2019-07-12 18:54:12.841342: Iteration 2: 0.12
2019-07-12 18:54:12.940728: Iteration 3: 0.10
2019-07-12 18:54:13.033057: Iteration 4: 0.09
2019-07-12 18:54:13.149254: Iteration 5: 0.12
2019-07-12 18:54:13.258663: Iteration 6: 0.11
2019-07-12 18:54:13.334502: Iteration 7: 0.07
2019-07-12 18:54:13.402137: Iteration 8: 0.07
2019-07-12 18:54:13.461559: Iteration 9: 0.06
2019-07-12 18:54:13.534043: Iteration 10: 0.07
2019-07-12 18:54:13.535087: 
2019-07-12 18:54:13.535108: Results for 1 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:54:13.536130: Actual rows fetched: 1
2019-07-12 18:54:13.536639: Time to execute select: 0.15 seconds
2019-07-12 18:54:13.537177: Time to put into dataframe: 0.09 seconds
2019-07-12 18:54:13.537658: Total time: 0.24 seconds
2019-07-12 18:54:13.714059: Iteration 0: 0.18
2019-07-12 18:54:13.829932: Iteration 1: 0.11
2019-07-12 18:54:13.999412: Iteration 2: 0.17
2019-07-12 18:54:14.115224: Iteration 3: 0.11
2019-07-12 18:54:14.182758: Iteration 4: 0.07
2019-07-12 18:54:14.281915: Iteration 5: 0.10
2019-07-12 18:54:14.369212: Iteration 6: 0.09
2019-07-12 18:54:14.451046: Iteration 7: 0.08
2019-07-12 18:54:14.566970: Iteration 8: 0.12
2019-07-12 18:54:14.653325: Iteration 9: 0.09
2019-07-12 18:54:14.736142: Iteration 10: 0.08
2019-07-12 18:54:14.736921: 
2019-07-12 18:54:14.736935: Results for 10 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:54:14.737628: Actual rows fetched: 10
2019-07-12 18:54:14.738037: Time to execute select: 0.10 seconds
2019-07-12 18:54:14.738428: Time to put into dataframe: 0.01 seconds
2019-07-12 18:54:14.738772: Total time: 0.11 seconds
2019-07-12 18:54:14.856877: Iteration 0: 0.12
2019-07-12 18:54:14.960240: Iteration 1: 0.10
2019-07-12 18:54:15.057007: Iteration 2: 0.10
2019-07-12 18:54:15.158074: Iteration 3: 0.10
2019-07-12 18:54:15.265950: Iteration 4: 0.11
2019-07-12 18:54:15.367082: Iteration 5: 0.10
2019-07-12 18:54:15.481900: Iteration 6: 0.11
2019-07-12 18:54:15.626789: Iteration 7: 0.14
2019-07-12 18:54:15.778807: Iteration 8: 0.15
2019-07-12 18:54:15.899236: Iteration 9: 0.12
2019-07-12 18:54:15.990880: Iteration 10: 0.09
2019-07-12 18:54:15.991565: 
2019-07-12 18:54:15.991579: Results for 100 records averaged over 11 repetitions with schema type NEW:
2019-07-12 18:54:15.992371: Actual rows fetched: 12
2019-07-12 18:54:15.992687: Time to execute select: 0.11 seconds
2019-07-12 18:54:15.993039: Time to put into dataframe: 0.01 seconds
2019-07-12 18:54:15.993447: Total time: 0.11 seconds
2019-07-12 18:55:48.660334: 
2019-07-12 18:55:48.660374: 
2019-07-12 18:55:48.660374: Beginning Cassandra Test
2019-07-12 18:55:49.011765: 
2019-07-12 18:55:49.011778: Current Query: Bulk Retrieval
2019-07-12 18:55:49.920697: Iteration 0: 0.04
2019-07-12 18:55:49.950429: Iteration 1: 0.03
2019-07-12 18:55:49.973040: Iteration 2: 0.02
2019-07-12 18:55:49.991933: Iteration 3: 0.02
2019-07-12 18:55:50.011724: Iteration 4: 0.02
2019-07-12 18:55:50.029276: Iteration 5: 0.02
2019-07-12 18:55:50.046974: Iteration 6: 0.02
2019-07-12 18:55:50.064655: Iteration 7: 0.02
2019-07-12 18:55:50.082916: Iteration 8: 0.02
2019-07-12 18:55:50.100510: Iteration 9: 0.02
2019-07-12 18:55:50.119386: Iteration 10: 0.02
2019-07-12 18:55:50.120090: 
2019-07-12 18:55:50.120099: Results for 1 records averaged over 11 repetitions:
2019-07-12 18:55:50.121104: Actual rows fetched: 1
2019-07-12 18:55:50.121515: Time to execute select: 0.02 seconds
2019-07-12 18:55:50.121903: Time to put into dataframe: 0.01 seconds
2019-07-12 18:55:50.122293: Total time: 0.02 seconds
2019-07-12 18:55:50.292805: Iteration 0: 0.04
2019-07-12 18:55:50.314670: Iteration 1: 0.02
2019-07-12 18:55:50.334692: Iteration 2: 0.02
2019-07-12 18:55:50.359579: Iteration 3: 0.02
2019-07-12 18:55:50.378394: Iteration 4: 0.02
2019-07-12 18:55:50.401433: Iteration 5: 0.02
2019-07-12 18:55:50.424180: Iteration 6: 0.02
2019-07-12 18:55:50.444788: Iteration 7: 0.02
2019-07-12 18:55:50.466359: Iteration 8: 0.02
2019-07-12 18:55:50.486340: Iteration 9: 0.02
2019-07-12 18:55:50.508815: Iteration 10: 0.02
2019-07-12 18:55:50.509455: 
2019-07-12 18:55:50.509464: Results for 10 records averaged over 11 repetitions:
2019-07-12 18:55:50.510009: Actual rows fetched: 10
2019-07-12 18:55:50.510387: Time to execute select: 0.02 seconds
2019-07-12 18:55:50.510719: Time to put into dataframe: 0.00 seconds
2019-07-12 18:55:50.510907: Total time: 0.02 seconds
2019-07-12 18:55:50.740984: Iteration 0: 0.08
2019-07-12 18:55:50.785627: Iteration 1: 0.04
2019-07-12 18:55:50.842271: Iteration 2: 0.06
2019-07-12 18:55:50.896113: Iteration 3: 0.05
2019-07-12 18:55:50.947459: Iteration 4: 0.05
2019-07-12 18:55:51.059930: Iteration 5: 0.11
2019-07-12 18:55:51.116790: Iteration 6: 0.06
2019-07-12 18:55:51.184416: Iteration 7: 0.07
2019-07-12 18:55:51.234110: Iteration 8: 0.05
2019-07-12 18:55:51.271928: Iteration 9: 0.04
2019-07-12 18:55:51.325459: Iteration 10: 0.05
2019-07-12 18:55:51.326073: 
2019-07-12 18:55:51.326081: Results for 100 records averaged over 11 repetitions:
2019-07-12 18:55:51.326840: Actual rows fetched: 100
2019-07-12 18:55:51.327233: Time to execute select: 0.05 seconds
2019-07-12 18:55:51.327624: Time to put into dataframe: 0.01 seconds
2019-07-12 18:55:51.328012: Total time: 0.06 seconds
2019-07-12 18:55:51.848305: Iteration 0: 0.40
2019-07-12 18:55:52.379155: Iteration 1: 0.53
2019-07-12 18:55:52.939428: Iteration 2: 0.56
2019-07-12 18:55:53.384446: Iteration 3: 0.44
2019-07-12 18:55:54.425570: Iteration 4: 1.04
2019-07-12 18:55:54.907033: Iteration 5: 0.48
2019-07-12 18:55:55.299878: Iteration 6: 0.39
2019-07-12 18:55:55.577781: Iteration 7: 0.28
2019-07-12 18:55:56.167560: Iteration 8: 0.59
2019-07-12 18:55:56.610003: Iteration 9: 0.44
2019-07-12 18:55:57.068173: Iteration 10: 0.46
2019-07-12 18:55:57.068811: 
2019-07-12 18:55:57.068819: Results for 1000 records averaged over 11 repetitions:
2019-07-12 18:55:57.069567: Actual rows fetched: 1000
2019-07-12 18:55:57.069951: Time to execute select: 0.50 seconds
2019-07-12 18:55:57.070340: Time to put into dataframe: 0.01 seconds
2019-07-12 18:55:57.070803: Total time: 0.51 seconds
2019-07-12 18:56:01.049329: Iteration 0: 3.84
2019-07-12 18:56:04.178705: Iteration 1: 3.13
2019-07-12 18:56:07.747219: Iteration 2: 3.57
2019-07-12 18:56:11.750010: Iteration 3: 4.00
2019-07-12 18:56:14.854350: Iteration 4: 3.10
2019-07-12 18:56:18.914820: Iteration 5: 4.06
2019-07-12 18:56:22.461064: Iteration 6: 3.55
2019-07-12 18:56:25.640030: Iteration 7: 3.18
2019-07-12 18:56:29.185288: Iteration 8: 3.54
2019-07-12 18:56:31.758062: Iteration 9: 2.57
2019-07-12 18:56:34.966111: Iteration 10: 3.21
2019-07-12 18:56:34.966612: 
2019-07-12 18:56:34.966621: Results for 10000 records averaged over 11 repetitions:
2019-07-12 18:56:34.967332: Actual rows fetched: 10000
2019-07-12 18:56:34.967715: Time to execute select: 3.32 seconds
2019-07-12 18:56:34.968104: Time to put into dataframe: 0.11 seconds
2019-07-12 18:56:34.968495: Total time: 3.43 seconds
2019-07-12 18:56:55.299821: Iteration 0: 20.21
2019-07-12 18:57:15.727350: Iteration 1: 20.43
2019-07-12 18:57:35.651578: Iteration 2: 19.92
2019-07-12 18:57:55.475329: Iteration 3: 19.82
2019-07-12 18:58:16.291323: Iteration 4: 20.82
2019-07-12 18:58:37.914140: Iteration 5: 21.62
2019-07-12 18:58:59.662556: Iteration 6: 21.75
2019-07-12 18:59:22.468914: Iteration 7: 22.81
2019-07-12 18:59:42.763368: Iteration 8: 20.29
2019-07-12 19:00:03.352917: Iteration 9: 20.59
2019-07-12 19:00:24.246216: Iteration 10: 20.89
2019-07-12 19:00:24.246727: 
2019-07-12 19:00:24.246735: Results for 100000 records averaged over 11 repetitions:
2019-07-12 19:00:24.247521: Actual rows fetched: 100000
2019-07-12 19:00:24.247912: Time to execute select: 19.40 seconds
2019-07-12 19:00:24.248305: Time to put into dataframe: 1.44 seconds
2019-07-12 19:00:24.248551: Total time: 20.83 seconds
2019-07-12 19:03:50.768446: Iteration 0: 206.40
2019-07-12 19:07:15.302956: Iteration 1: 204.53
2019-07-12 19:10:26.768415: Iteration 2: 191.46
2019-07-12 19:13:30.587511: Iteration 3: 183.82
2019-07-12 19:16:47.590117: Iteration 4: 197.00
2019-07-12 19:19:50.131200: Iteration 5: 182.54
2019-07-12 19:22:59.763551: Iteration 6: 189.63
2019-07-12 19:26:06.734239: Iteration 7: 186.97
2019-07-12 19:29:08.762889: Iteration 8: 182.02
